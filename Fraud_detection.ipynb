{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c170e9-ff71-4881-aaf1-383482871c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afd9d6e9-ce49-41d8-a0ca-88eb05c372fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"C:\\\\Users\\\\Aditya Mishra\\\\Downloads\\\\Dataset-1.csv\") [:80000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdfa1526-4060-451f-afa2-8d54239b3646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>37332.183588</td>\n",
       "      <td>15209.718131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30718.500000</td>\n",
       "      <td>40052.000000</td>\n",
       "      <td>49105.000000</td>\n",
       "      <td>58287.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.258086</td>\n",
       "      <td>1.888947</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-1.019388</td>\n",
       "      <td>-0.250144</td>\n",
       "      <td>1.153620</td>\n",
       "      <td>1.960497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.036364</td>\n",
       "      <td>1.679465</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.599350</td>\n",
       "      <td>0.069013</td>\n",
       "      <td>0.721751</td>\n",
       "      <td>18.902453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.678340</td>\n",
       "      <td>1.386402</td>\n",
       "      <td>-33.680984</td>\n",
       "      <td>0.186697</td>\n",
       "      <td>0.765189</td>\n",
       "      <td>1.394244</td>\n",
       "      <td>4.226108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>1.368678</td>\n",
       "      <td>-5.172595</td>\n",
       "      <td>-0.725926</td>\n",
       "      <td>0.182134</td>\n",
       "      <td>1.043840</td>\n",
       "      <td>16.715537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.276254</td>\n",
       "      <td>1.382928</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-0.894690</td>\n",
       "      <td>-0.309687</td>\n",
       "      <td>0.258717</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.095376</td>\n",
       "      <td>1.305057</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.642417</td>\n",
       "      <td>-0.153999</td>\n",
       "      <td>0.490107</td>\n",
       "      <td>22.529298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.114390</td>\n",
       "      <td>1.247498</td>\n",
       "      <td>-31.764946</td>\n",
       "      <td>-0.604450</td>\n",
       "      <td>-0.073816</td>\n",
       "      <td>0.416536</td>\n",
       "      <td>36.677268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.053252</td>\n",
       "      <td>1.233289</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.141200</td>\n",
       "      <td>0.069079</td>\n",
       "      <td>0.349036</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>1.144390</td>\n",
       "      <td>-9.283925</td>\n",
       "      <td>-0.686546</td>\n",
       "      <td>-0.089189</td>\n",
       "      <td>0.624249</td>\n",
       "      <td>10.392889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.033035</td>\n",
       "      <td>1.077095</td>\n",
       "      <td>-18.271168</td>\n",
       "      <td>-0.504613</td>\n",
       "      <td>-0.095363</td>\n",
       "      <td>0.441298</td>\n",
       "      <td>13.198226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.282333</td>\n",
       "      <td>1.080885</td>\n",
       "      <td>-4.049895</td>\n",
       "      <td>-0.503180</td>\n",
       "      <td>0.218574</td>\n",
       "      <td>1.091806</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.135331</td>\n",
       "      <td>1.181728</td>\n",
       "      <td>-17.769143</td>\n",
       "      <td>-0.576481</td>\n",
       "      <td>0.078274</td>\n",
       "      <td>0.604365</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.046475</td>\n",
       "      <td>1.062442</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.657197</td>\n",
       "      <td>0.018713</td>\n",
       "      <td>0.736451</td>\n",
       "      <td>4.465413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.086438</td>\n",
       "      <td>1.009223</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.325542</td>\n",
       "      <td>0.092592</td>\n",
       "      <td>0.525140</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.168353</td>\n",
       "      <td>0.934943</td>\n",
       "      <td>-4.152532</td>\n",
       "      <td>-0.387215</td>\n",
       "      <td>0.273084</td>\n",
       "      <td>0.843304</td>\n",
       "      <td>5.784514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.006601</td>\n",
       "      <td>0.915172</td>\n",
       "      <td>-13.563273</td>\n",
       "      <td>-0.485078</td>\n",
       "      <td>0.064121</td>\n",
       "      <td>0.545941</td>\n",
       "      <td>6.098529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.073443</td>\n",
       "      <td>0.991223</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.390655</td>\n",
       "      <td>0.015696</td>\n",
       "      <td>0.481426</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.097295</td>\n",
       "      <td>0.856804</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.572621</td>\n",
       "      <td>-0.087411</td>\n",
       "      <td>0.393335</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.022084</td>\n",
       "      <td>0.820865</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.518258</td>\n",
       "      <td>-0.026718</td>\n",
       "      <td>0.484141</td>\n",
       "      <td>5.228342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.042138</td>\n",
       "      <td>0.769819</td>\n",
       "      <td>-19.902611</td>\n",
       "      <td>-0.169341</td>\n",
       "      <td>-0.024952</td>\n",
       "      <td>0.170681</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.029000</td>\n",
       "      <td>0.739825</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.224356</td>\n",
       "      <td>-0.058577</td>\n",
       "      <td>0.117690</td>\n",
       "      <td>22.614889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.105751</td>\n",
       "      <td>0.636423</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.524838</td>\n",
       "      <td>-0.080453</td>\n",
       "      <td>0.309546</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>-0.037651</td>\n",
       "      <td>0.628525</td>\n",
       "      <td>-26.751119</td>\n",
       "      <td>-0.178315</td>\n",
       "      <td>-0.050284</td>\n",
       "      <td>0.080590</td>\n",
       "      <td>18.946734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.595679</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.322913</td>\n",
       "      <td>0.064108</td>\n",
       "      <td>0.405444</td>\n",
       "      <td>4.014444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.134427</td>\n",
       "      <td>0.440853</td>\n",
       "      <td>-7.495741</td>\n",
       "      <td>-0.129354</td>\n",
       "      <td>0.172777</td>\n",
       "      <td>0.421519</td>\n",
       "      <td>5.525093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.026336</td>\n",
       "      <td>0.498120</td>\n",
       "      <td>-2.534330</td>\n",
       "      <td>-0.326741</td>\n",
       "      <td>-0.072778</td>\n",
       "      <td>0.307898</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.390666</td>\n",
       "      <td>-9.390980</td>\n",
       "      <td>-0.063341</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.082446</td>\n",
       "      <td>12.152401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.331055</td>\n",
       "      <td>-9.617915</td>\n",
       "      <td>-0.005819</td>\n",
       "      <td>0.022868</td>\n",
       "      <td>0.076056</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>97.775498</td>\n",
       "      <td>269.180362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.680000</td>\n",
       "      <td>26.955000</td>\n",
       "      <td>89.205000</td>\n",
       "      <td>19656.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.049437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count          mean           std        min           25%  \\\n",
       "Time    80000.0  37332.183588  15209.718131   0.000000  30718.500000   \n",
       "V1      80000.0     -0.258086      1.888947 -56.407510     -1.019388   \n",
       "V2      80000.0     -0.036364      1.679465 -72.715728     -0.599350   \n",
       "V3      80000.0      0.678340      1.386402 -33.680984      0.186697   \n",
       "V4      80000.0      0.163600      1.368678  -5.172595     -0.725926   \n",
       "V5      80000.0     -0.276254      1.382928 -42.147898     -0.894690   \n",
       "V6      80000.0      0.095376      1.305057 -26.160506     -0.642417   \n",
       "V7      80000.0     -0.114390      1.247498 -31.764946     -0.604450   \n",
       "V8      80000.0      0.053252      1.233289 -73.216718     -0.141200   \n",
       "V9      80000.0     -0.010000      1.144390  -9.283925     -0.686546   \n",
       "V10     80000.0     -0.033035      1.077095 -18.271168     -0.504613   \n",
       "V11     80000.0      0.282333      1.080885  -4.049895     -0.503180   \n",
       "V12     80000.0     -0.135331      1.181728 -17.769143     -0.576481   \n",
       "V13     80000.0      0.046475      1.062442  -5.791881     -0.657197   \n",
       "V14     80000.0      0.086438      1.009223 -19.214325     -0.325542   \n",
       "V15     80000.0      0.168353      0.934943  -4.152532     -0.387215   \n",
       "V16     80000.0     -0.006601      0.915172 -13.563273     -0.485078   \n",
       "V17     80000.0      0.073443      0.991223 -25.162799     -0.390655   \n",
       "V18     80000.0     -0.097295      0.856804  -9.498746     -0.572621   \n",
       "V19     80000.0     -0.022084      0.820865  -7.213527     -0.518258   \n",
       "V20     80000.0      0.042138      0.769819 -19.902611     -0.169341   \n",
       "V21     80000.0     -0.029000      0.739825 -34.830382     -0.224356   \n",
       "V22     80000.0     -0.105751      0.636423 -10.933144     -0.524838   \n",
       "V23     80000.0     -0.037651      0.628525 -26.751119     -0.178315   \n",
       "V24     80000.0      0.007894      0.595679  -2.836627     -0.322913   \n",
       "V25     80000.0      0.134427      0.440853  -7.495741     -0.129354   \n",
       "V26     80000.0      0.026336      0.498120  -2.534330     -0.326741   \n",
       "V27     80000.0      0.002025      0.390666  -9.390980     -0.063341   \n",
       "V28     80000.0      0.002570      0.331055  -9.617915     -0.005819   \n",
       "Amount  80000.0     97.775498    269.180362   0.000000      7.680000   \n",
       "Class   80000.0      0.002450      0.049437   0.000000      0.000000   \n",
       "\n",
       "                 50%           75%           max  \n",
       "Time    40052.000000  49105.000000  58287.000000  \n",
       "V1         -0.250144      1.153620      1.960497  \n",
       "V2          0.069013      0.721751     18.902453  \n",
       "V3          0.765189      1.394244      4.226108  \n",
       "V4          0.182134      1.043840     16.715537  \n",
       "V5         -0.309687      0.258717     34.801666  \n",
       "V6         -0.153999      0.490107     22.529298  \n",
       "V7         -0.073816      0.416536     36.677268  \n",
       "V8          0.069079      0.349036     20.007208  \n",
       "V9         -0.089189      0.624249     10.392889  \n",
       "V10        -0.095363      0.441298     13.198226  \n",
       "V11         0.218574      1.091806     12.018913  \n",
       "V12         0.078274      0.604365      7.848392  \n",
       "V13         0.018713      0.736451      4.465413  \n",
       "V14         0.092592      0.525140     10.526766  \n",
       "V15         0.273084      0.843304      5.784514  \n",
       "V16         0.064121      0.545941      6.098529  \n",
       "V17         0.015696      0.481426      9.253526  \n",
       "V18        -0.087411      0.393335      5.041069  \n",
       "V19        -0.026718      0.484141      5.228342  \n",
       "V20        -0.024952      0.170681     39.420904  \n",
       "V21        -0.058577      0.117690     22.614889  \n",
       "V22        -0.080453      0.309546     10.503090  \n",
       "V23        -0.050284      0.080590     18.946734  \n",
       "V24         0.064108      0.405444      4.014444  \n",
       "V25         0.172777      0.421519      5.525093  \n",
       "V26        -0.072778      0.307898      3.517346  \n",
       "V27         0.009277      0.082446     12.152401  \n",
       "V28         0.022868      0.076056     33.847808  \n",
       "Amount     26.955000     89.205000  19656.530000  \n",
       "Class       0.000000      0.000000      1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5beb0d48-e6c4-4062-b5b6-789f3758bd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X shape :(80000, 28) and y: (80000,) Fraud Cases : 0.245'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X  = df.drop(['Time','Amount','Class'] , axis='columns').values\n",
    "y =  df['Class'].values\n",
    "f\"X shape :{X.shape} and y: {y.shape} Fraud Cases : {(y.sum()/len(df))*100}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "385dab14-73b5-49a8-8c6b-f87fcf20e453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}]})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight={0: 1, 1: 1}, max_iter=1000)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight={0: 1, 1: 1}, max_iter=1000)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000),\n",
       "             param_grid={'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 2},\n",
       "                                          {0: 1, 1: 3}]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "mod = LogisticRegression(class_weight = {0:1,1:2} ).fit(X,y).predict(X).sum()\n",
    "mod\n",
    "from sklearn.model_selection  import GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter = 1000), \n",
    "    param_grid ={ 'class_weight'  :[{0:1,1:v} for v in range(1,4)]},\n",
    "    cv  = 5\n",
    ")\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aaa6ea-f2c7-4d01-b6a1-50dc9753c619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf239747-7640-487b-8260-60615af70e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.182151</td>\n",
       "      <td>0.233814</td>\n",
       "      <td>0.21699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.032773</td>\n",
       "      <td>0.037592</td>\n",
       "      <td>0.018999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.003132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_class_weight</th>\n",
       "      <td>{0: 1, 1: 1}</td>\n",
       "      <td>{0: 1, 1: 2}</td>\n",
       "      <td>{0: 1, 1: 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'class_weight': {0: 1, 1: 1}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.526563</td>\n",
       "      <td>0.472187</td>\n",
       "      <td>0.459062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.998375</td>\n",
       "      <td>0.998875</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.999062</td>\n",
       "      <td>0.999125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.999062</td>\n",
       "      <td>0.999188</td>\n",
       "      <td>0.999188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.997812</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.998437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.904162</td>\n",
       "      <td>0.893512</td>\n",
       "      <td>0.890962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.188801</td>\n",
       "      <td>0.210663</td>\n",
       "      <td>0.21595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 0  \\\n",
       "mean_fit_time                             0.182151   \n",
       "std_fit_time                              0.032773   \n",
       "mean_score_time                           0.003015   \n",
       "std_score_time                            0.000215   \n",
       "param_class_weight                    {0: 1, 1: 1}   \n",
       "params              {'class_weight': {0: 1, 1: 1}}   \n",
       "split0_test_score                         0.526563   \n",
       "split1_test_score                         0.998375   \n",
       "split2_test_score                            0.999   \n",
       "split3_test_score                         0.999062   \n",
       "split4_test_score                         0.997812   \n",
       "mean_test_score                           0.904162   \n",
       "std_test_score                            0.188801   \n",
       "rank_test_score                                  1   \n",
       "\n",
       "                                                 1  \\\n",
       "mean_fit_time                             0.233814   \n",
       "std_fit_time                              0.037592   \n",
       "mean_score_time                           0.003064   \n",
       "std_score_time                            0.000311   \n",
       "param_class_weight                    {0: 1, 1: 2}   \n",
       "params              {'class_weight': {0: 1, 1: 2}}   \n",
       "split0_test_score                         0.472187   \n",
       "split1_test_score                         0.998875   \n",
       "split2_test_score                         0.999062   \n",
       "split3_test_score                         0.999188   \n",
       "split4_test_score                          0.99825   \n",
       "mean_test_score                           0.893512   \n",
       "std_test_score                            0.210663   \n",
       "rank_test_score                                  2   \n",
       "\n",
       "                                                 2  \n",
       "mean_fit_time                              0.21699  \n",
       "std_fit_time                              0.018999  \n",
       "mean_score_time                           0.003132  \n",
       "std_score_time                            0.000344  \n",
       "param_class_weight                    {0: 1, 1: 3}  \n",
       "params              {'class_weight': {0: 1, 1: 3}}  \n",
       "split0_test_score                         0.459062  \n",
       "split1_test_score                            0.999  \n",
       "split2_test_score                         0.999125  \n",
       "split3_test_score                         0.999188  \n",
       "split4_test_score                         0.998437  \n",
       "mean_test_score                           0.890962  \n",
       "std_test_score                             0.21595  \n",
       "rank_test_score                                  3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.DataFrame(grid.cv_results_)\n",
    "df_new.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49f9dafd-af2b-43da-8932-e21ac734e854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6020408163265306"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score , recall_score , make_scorer\n",
    "precision_score(y,grid.predict(X))\n",
    "recall_score(y,grid.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cccc2ee-3fc7-48ee-be88-61458d0eb0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: np.float64(0.0)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(0.6896551724137931)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(1.3793103448275863)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.0689655172413794)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.7586206896551726)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(3.4482758620689657)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(4.1379310344...\n",
       "                                           1: np.float64(17.24137931034483)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(17.931034482758623)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(18.620689655172416)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(19.310344827586206)},\n",
       "                                          {0: 1, 1: np.float64(20.0)}]},\n",
       "             refit=&#x27;precision&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: np.float64(0.0)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(0.6896551724137931)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(1.3793103448275863)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.0689655172413794)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.7586206896551726)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(3.4482758620689657)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(4.1379310344...\n",
       "                                           1: np.float64(17.24137931034483)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(17.931034482758623)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(18.620689655172416)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(19.310344827586206)},\n",
       "                                          {0: 1, 1: np.float64(20.0)}]},\n",
       "             refit=&#x27;precision&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;)})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight={0: 1, 1: np.float64(2.0689655172413794)},\n",
       "                   max_iter=1000)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight={0: 1, 1: np.float64(2.0689655172413794)},\n",
       "                   max_iter=1000)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 1, 1: np.float64(0.0)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(0.6896551724137931)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(1.3793103448275863)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.0689655172413794)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.7586206896551726)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(3.4482758620689657)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(4.1379310344...\n",
       "                                           1: np.float64(17.24137931034483)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(17.931034482758623)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(18.620689655172416)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(19.310344827586206)},\n",
       "                                          {0: 1, 1: np.float64(20.0)}]},\n",
       "             refit='precision', return_train_score=True,\n",
       "             scoring={'precision': make_scorer(precision_score, response_method='predict'),\n",
       "                      'recall': make_scorer(recall_score, response_method='predict')})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter = 1000), \n",
    "    param_grid ={ 'class_weight'  :[{0:1,1:v} for v in np.linspace(0,20,30)]},\n",
    "    scoring = {'precision':make_scorer(precision_score) ,'recall' : make_scorer(recall_score)}, \n",
    "    refit = 'precision',\n",
    "    return_train_score = True,\n",
    "    cv  = 10,\n",
    "    n_jobs = -1\n",
    ")\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2703ce42-67d3-49c1-9283-8c06247e4b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.29938</td>\n",
       "      <td>0.657827</td>\n",
       "      <td>0.823051</td>\n",
       "      <td>1.07487</td>\n",
       "      <td>0.996487</td>\n",
       "      <td>1.038066</td>\n",
       "      <td>0.923621</td>\n",
       "      <td>1.042718</td>\n",
       "      <td>0.946644</td>\n",
       "      <td>0.954515</td>\n",
       "      <td>...</td>\n",
       "      <td>1.358662</td>\n",
       "      <td>1.231279</td>\n",
       "      <td>1.412879</td>\n",
       "      <td>1.265294</td>\n",
       "      <td>1.296301</td>\n",
       "      <td>1.420746</td>\n",
       "      <td>1.365398</td>\n",
       "      <td>1.522262</td>\n",
       "      <td>1.359854</td>\n",
       "      <td>1.10281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.08343</td>\n",
       "      <td>0.183603</td>\n",
       "      <td>0.21349</td>\n",
       "      <td>0.447706</td>\n",
       "      <td>0.39674</td>\n",
       "      <td>0.56174</td>\n",
       "      <td>0.243622</td>\n",
       "      <td>0.457954</td>\n",
       "      <td>0.283909</td>\n",
       "      <td>0.168779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427797</td>\n",
       "      <td>0.487817</td>\n",
       "      <td>0.385397</td>\n",
       "      <td>0.404825</td>\n",
       "      <td>0.39978</td>\n",
       "      <td>0.57186</td>\n",
       "      <td>0.562338</td>\n",
       "      <td>0.490938</td>\n",
       "      <td>0.365732</td>\n",
       "      <td>0.222626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.049396</td>\n",
       "      <td>0.046291</td>\n",
       "      <td>0.041323</td>\n",
       "      <td>0.039542</td>\n",
       "      <td>0.071222</td>\n",
       "      <td>0.041214</td>\n",
       "      <td>0.05615</td>\n",
       "      <td>0.059822</td>\n",
       "      <td>0.04353</td>\n",
       "      <td>0.044313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045166</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.098305</td>\n",
       "      <td>0.036948</td>\n",
       "      <td>0.042273</td>\n",
       "      <td>0.079623</td>\n",
       "      <td>0.044323</td>\n",
       "      <td>0.06233</td>\n",
       "      <td>0.045622</td>\n",
       "      <td>0.028376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.017189</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.05777</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>0.063112</td>\n",
       "      <td>0.030604</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.009966</td>\n",
       "      <td>0.123807</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.092874</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>0.027572</td>\n",
       "      <td>0.014369</td>\n",
       "      <td>0.011769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_class_weight</th>\n",
       "      <td>{0: 1, 1: 0.0}</td>\n",
       "      <td>{0: 1, 1: 0.6896551724137931}</td>\n",
       "      <td>{0: 1, 1: 1.3793103448275863}</td>\n",
       "      <td>{0: 1, 1: 2.0689655172413794}</td>\n",
       "      <td>{0: 1, 1: 2.7586206896551726}</td>\n",
       "      <td>{0: 1, 1: 3.4482758620689657}</td>\n",
       "      <td>{0: 1, 1: 4.137931034482759}</td>\n",
       "      <td>{0: 1, 1: 4.827586206896552}</td>\n",
       "      <td>{0: 1, 1: 5.517241379310345}</td>\n",
       "      <td>{0: 1, 1: 6.206896551724139}</td>\n",
       "      <td>...</td>\n",
       "      <td>{0: 1, 1: 13.793103448275863}</td>\n",
       "      <td>{0: 1, 1: 14.482758620689657}</td>\n",
       "      <td>{0: 1, 1: 15.172413793103448}</td>\n",
       "      <td>{0: 1, 1: 15.862068965517242}</td>\n",
       "      <td>{0: 1, 1: 16.551724137931036}</td>\n",
       "      <td>{0: 1, 1: 17.24137931034483}</td>\n",
       "      <td>{0: 1, 1: 17.931034482758623}</td>\n",
       "      <td>{0: 1, 1: 18.620689655172416}</td>\n",
       "      <td>{0: 1, 1: 19.310344827586206}</td>\n",
       "      <td>{0: 1, 1: 20.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'class_weight': {0: 1, 1: 0.0}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 0.6896551724137931}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.3793103448275863}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.0689655172413794}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.7586206896551726}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3.4482758620689657}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.137931034482759}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.827586206896552}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 5.517241379310345}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.206896551724139}}</td>\n",
       "      <td>...</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 13.793103448275863}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.482758620689657}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 15.172413793103448}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 15.862068965517242}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.551724137931036}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 17.24137931034483}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 17.931034482758623}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.620689655172416}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 19.310344827586206}}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 20.0}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.787314</td>\n",
       "      <td>0.878782</td>\n",
       "      <td>0.880297</td>\n",
       "      <td>0.87215</td>\n",
       "      <td>0.872626</td>\n",
       "      <td>0.872626</td>\n",
       "      <td>0.874693</td>\n",
       "      <td>0.870821</td>\n",
       "      <td>0.866384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84274</td>\n",
       "      <td>0.837511</td>\n",
       "      <td>0.835086</td>\n",
       "      <td>0.81556</td>\n",
       "      <td>0.811374</td>\n",
       "      <td>0.803092</td>\n",
       "      <td>0.795491</td>\n",
       "      <td>0.788547</td>\n",
       "      <td>0.783983</td>\n",
       "      <td>0.776555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320224</td>\n",
       "      <td>0.193478</td>\n",
       "      <td>0.193056</td>\n",
       "      <td>0.192081</td>\n",
       "      <td>0.192226</td>\n",
       "      <td>0.192226</td>\n",
       "      <td>0.19226</td>\n",
       "      <td>0.190923</td>\n",
       "      <td>0.190221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189773</td>\n",
       "      <td>0.187697</td>\n",
       "      <td>0.193352</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.190916</td>\n",
       "      <td>0.190198</td>\n",
       "      <td>0.195495</td>\n",
       "      <td>0.195462</td>\n",
       "      <td>0.197189</td>\n",
       "      <td>0.199616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_precision</th>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.782313</td>\n",
       "      <td>0.770701</td>\n",
       "      <td>0.776398</td>\n",
       "      <td>0.784431</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.80226</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.80663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.780612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.91875</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.919753</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.850829</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.832432</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.806283</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.789744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.872881</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.845679</td>\n",
       "      <td>0.850299</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816754</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.791878</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.760976</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.758865</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.785276</td>\n",
       "      <td>0.792899</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794737</td>\n",
       "      <td>0.787565</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.787565</td>\n",
       "      <td>0.787565</td>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.77665</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.768844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.768707</td>\n",
       "      <td>0.786164</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.796407</td>\n",
       "      <td>0.796512</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.805405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.797927</td>\n",
       "      <td>0.793814</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.754902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.802326</td>\n",
       "      <td>0.80791</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.794737</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.792746</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.785276</td>\n",
       "      <td>0.792899</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78836</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.777202</td>\n",
       "      <td>0.777202</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.762626</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.740196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.804734</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792746</td>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.780612</td>\n",
       "      <td>0.780612</td>\n",
       "      <td>0.768844</td>\n",
       "      <td>0.753695</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.80663</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790816</td>\n",
       "      <td>0.791878</td>\n",
       "      <td>0.78392</td>\n",
       "      <td>0.78392</td>\n",
       "      <td>0.78392</td>\n",
       "      <td>0.78392</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.78607</td>\n",
       "      <td>0.781095</td>\n",
       "      <td>0.782178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.782258</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.790419</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.798851</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.797927</td>\n",
       "      <td>0.78866</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.781726</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.790305</td>\n",
       "      <td>0.798779</td>\n",
       "      <td>0.806776</td>\n",
       "      <td>0.810822</td>\n",
       "      <td>0.81447</td>\n",
       "      <td>0.818695</td>\n",
       "      <td>0.819219</td>\n",
       "      <td>0.821165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80434</td>\n",
       "      <td>0.800654</td>\n",
       "      <td>0.797373</td>\n",
       "      <td>0.794066</td>\n",
       "      <td>0.791549</td>\n",
       "      <td>0.786418</td>\n",
       "      <td>0.783732</td>\n",
       "      <td>0.778977</td>\n",
       "      <td>0.772918</td>\n",
       "      <td>0.770329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045762</td>\n",
       "      <td>0.048263</td>\n",
       "      <td>0.043774</td>\n",
       "      <td>0.04197</td>\n",
       "      <td>0.040675</td>\n",
       "      <td>0.037351</td>\n",
       "      <td>0.035115</td>\n",
       "      <td>0.030813</td>\n",
       "      <td>0.031863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021629</td>\n",
       "      <td>0.020445</td>\n",
       "      <td>0.019071</td>\n",
       "      <td>0.012977</td>\n",
       "      <td>0.014744</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>0.012286</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.017186</td>\n",
       "      <td>0.01494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.502105</td>\n",
       "      <td>0.598947</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.665263</td>\n",
       "      <td>0.711842</td>\n",
       "      <td>0.732632</td>\n",
       "      <td>0.747632</td>\n",
       "      <td>0.767895</td>\n",
       "      <td>0.787895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838421</td>\n",
       "      <td>0.838421</td>\n",
       "      <td>0.838421</td>\n",
       "      <td>0.838421</td>\n",
       "      <td>0.838421</td>\n",
       "      <td>0.838421</td>\n",
       "      <td>0.838421</td>\n",
       "      <td>0.843421</td>\n",
       "      <td>0.843421</td>\n",
       "      <td>0.843421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306968</td>\n",
       "      <td>0.271005</td>\n",
       "      <td>0.244257</td>\n",
       "      <td>0.238894</td>\n",
       "      <td>0.218343</td>\n",
       "      <td>0.215999</td>\n",
       "      <td>0.211427</td>\n",
       "      <td>0.209612</td>\n",
       "      <td>0.183907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135567</td>\n",
       "      <td>0.135567</td>\n",
       "      <td>0.135567</td>\n",
       "      <td>0.135567</td>\n",
       "      <td>0.135567</td>\n",
       "      <td>0.135567</td>\n",
       "      <td>0.135567</td>\n",
       "      <td>0.127355</td>\n",
       "      <td>0.127355</td>\n",
       "      <td>0.127355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_recall</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.649718</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.751412</td>\n",
       "      <td>0.80226</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.864407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700565</td>\n",
       "      <td>0.79096</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.870056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581921</td>\n",
       "      <td>0.649718</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>0.80226</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.881356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514124</td>\n",
       "      <td>0.60452</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.757062</td>\n",
       "      <td>0.79096</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.864407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.642045</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split5_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.528409</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.693182</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split6_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505682</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.664773</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>0.857955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split7_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551136</td>\n",
       "      <td>0.664773</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split8_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.664773</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.767045</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.857955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.897727</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.897727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split9_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551136</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.869318</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563424</td>\n",
       "      <td>0.656992</td>\n",
       "      <td>0.709723</td>\n",
       "      <td>0.745438</td>\n",
       "      <td>0.764144</td>\n",
       "      <td>0.787388</td>\n",
       "      <td>0.811194</td>\n",
       "      <td>0.826515</td>\n",
       "      <td>0.838996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864513</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.867915</td>\n",
       "      <td>0.869052</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.869617</td>\n",
       "      <td>0.870185</td>\n",
       "      <td>0.871889</td>\n",
       "      <td>0.872454</td>\n",
       "      <td>0.873591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053126</td>\n",
       "      <td>0.048578</td>\n",
       "      <td>0.045741</td>\n",
       "      <td>0.039703</td>\n",
       "      <td>0.034982</td>\n",
       "      <td>0.031374</td>\n",
       "      <td>0.022743</td>\n",
       "      <td>0.015178</td>\n",
       "      <td>0.01399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.010509</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>0.010226</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.010851</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.010375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0   \\\n",
       "mean_fit_time                                    0.29938   \n",
       "std_fit_time                                     0.08343   \n",
       "mean_score_time                                 0.049396   \n",
       "std_score_time                                  0.017189   \n",
       "param_class_weight                        {0: 1, 1: 0.0}   \n",
       "params                  {'class_weight': {0: 1, 1: 0.0}}   \n",
       "split0_test_precision                                0.0   \n",
       "split1_test_precision                                0.0   \n",
       "split2_test_precision                                0.0   \n",
       "split3_test_precision                                0.0   \n",
       "split4_test_precision                                0.0   \n",
       "split5_test_precision                                0.0   \n",
       "split6_test_precision                                0.0   \n",
       "split7_test_precision                                0.0   \n",
       "split8_test_precision                                0.0   \n",
       "split9_test_precision                                0.0   \n",
       "mean_test_precision                                  0.0   \n",
       "std_test_precision                                   0.0   \n",
       "rank_test_precision                                   30   \n",
       "split0_train_precision                               0.0   \n",
       "split1_train_precision                               0.0   \n",
       "split2_train_precision                               0.0   \n",
       "split3_train_precision                               0.0   \n",
       "split4_train_precision                               0.0   \n",
       "split5_train_precision                               0.0   \n",
       "split6_train_precision                               0.0   \n",
       "split7_train_precision                               0.0   \n",
       "split8_train_precision                               0.0   \n",
       "split9_train_precision                               0.0   \n",
       "mean_train_precision                                 0.0   \n",
       "std_train_precision                                  0.0   \n",
       "split0_test_recall                                   0.0   \n",
       "split1_test_recall                                   0.0   \n",
       "split2_test_recall                                   0.0   \n",
       "split3_test_recall                                   0.0   \n",
       "split4_test_recall                                   0.0   \n",
       "split5_test_recall                                   0.0   \n",
       "split6_test_recall                                   0.0   \n",
       "split7_test_recall                                   0.0   \n",
       "split8_test_recall                                   0.0   \n",
       "split9_test_recall                                   0.0   \n",
       "mean_test_recall                                     0.0   \n",
       "std_test_recall                                      0.0   \n",
       "rank_test_recall                                      30   \n",
       "split0_train_recall                                  0.0   \n",
       "split1_train_recall                                  0.0   \n",
       "split2_train_recall                                  0.0   \n",
       "split3_train_recall                                  0.0   \n",
       "split4_train_recall                                  0.0   \n",
       "split5_train_recall                                  0.0   \n",
       "split6_train_recall                                  0.0   \n",
       "split7_train_recall                                  0.0   \n",
       "split8_train_recall                                  0.0   \n",
       "split9_train_recall                                  0.0   \n",
       "mean_train_recall                                    0.0   \n",
       "std_train_recall                                     0.0   \n",
       "\n",
       "                                                                     1   \\\n",
       "mean_fit_time                                                  0.657827   \n",
       "std_fit_time                                                   0.183603   \n",
       "mean_score_time                                                0.046291   \n",
       "std_score_time                                                 0.016161   \n",
       "param_class_weight                        {0: 1, 1: 0.6896551724137931}   \n",
       "params                  {'class_weight': {0: 1, 1: 0.6896551724137931}}   \n",
       "split0_test_precision                                               1.0   \n",
       "split1_test_precision                                          0.463415   \n",
       "split2_test_precision                                          0.583333   \n",
       "split3_test_precision                                               1.0   \n",
       "split4_test_precision                                               1.0   \n",
       "split5_test_precision                                            0.9375   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.888889   \n",
       "split8_test_precision                                               0.0   \n",
       "split9_test_precision                                               1.0   \n",
       "mean_test_precision                                            0.787314   \n",
       "std_test_precision                                             0.320224   \n",
       "rank_test_precision                                                  27   \n",
       "split0_train_precision                                         0.836066   \n",
       "split1_train_precision                                         0.911765   \n",
       "split2_train_precision                                         0.872881   \n",
       "split3_train_precision                                         0.791304   \n",
       "split4_train_precision                                         0.783333   \n",
       "split5_train_precision                                            0.775   \n",
       "split6_train_precision                                         0.760684   \n",
       "split7_train_precision                                         0.788618   \n",
       "split8_train_precision                                         0.806202   \n",
       "split9_train_precision                                         0.782258   \n",
       "mean_train_precision                                           0.810811   \n",
       "std_train_precision                                            0.045762   \n",
       "split0_test_recall                                             0.368421   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.736842   \n",
       "split3_test_recall                                             0.315789   \n",
       "split4_test_recall                                                 0.25   \n",
       "split5_test_recall                                                 0.75   \n",
       "split6_test_recall                                                  0.9   \n",
       "split7_test_recall                                                  0.4   \n",
       "split8_test_recall                                                  0.0   \n",
       "split9_test_recall                                                  0.3   \n",
       "mean_test_recall                                               0.502105   \n",
       "std_test_recall                                                0.306968   \n",
       "rank_test_recall                                                     29   \n",
       "split0_train_recall                                            0.576271   \n",
       "split1_train_recall                                            0.700565   \n",
       "split2_train_recall                                            0.581921   \n",
       "split3_train_recall                                            0.514124   \n",
       "split4_train_recall                                            0.534091   \n",
       "split5_train_recall                                            0.528409   \n",
       "split6_train_recall                                            0.505682   \n",
       "split7_train_recall                                            0.551136   \n",
       "split8_train_recall                                            0.590909   \n",
       "split9_train_recall                                            0.551136   \n",
       "mean_train_recall                                              0.563424   \n",
       "std_train_recall                                               0.053126   \n",
       "\n",
       "                                                                     2   \\\n",
       "mean_fit_time                                                  0.823051   \n",
       "std_fit_time                                                    0.21349   \n",
       "mean_score_time                                                0.041323   \n",
       "std_score_time                                                 0.017176   \n",
       "param_class_weight                        {0: 1, 1: 1.3793103448275863}   \n",
       "params                  {'class_weight': {0: 1, 1: 1.3793103448275863}}   \n",
       "split0_test_precision                                               1.0   \n",
       "split1_test_precision                                           0.44186   \n",
       "split2_test_precision                                          0.583333   \n",
       "split3_test_precision                                               1.0   \n",
       "split4_test_precision                                               1.0   \n",
       "split5_test_precision                                          0.944444   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.818182   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                               1.0   \n",
       "mean_test_precision                                            0.878782   \n",
       "std_test_precision                                             0.193478   \n",
       "rank_test_precision                                                   2   \n",
       "split0_train_precision                                         0.782313   \n",
       "split1_train_precision                                         0.921053   \n",
       "split2_train_precision                                         0.833333   \n",
       "split3_train_precision                                         0.758865   \n",
       "split4_train_precision                                         0.768707   \n",
       "split5_train_precision                                         0.763889   \n",
       "split6_train_precision                                         0.756944   \n",
       "split7_train_precision                                             0.78   \n",
       "split8_train_precision                                         0.769737   \n",
       "split9_train_precision                                         0.768212   \n",
       "mean_train_precision                                           0.790305   \n",
       "std_train_precision                                            0.048263   \n",
       "split0_test_recall                                             0.368421   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.736842   \n",
       "split3_test_recall                                             0.684211   \n",
       "split4_test_recall                                                 0.35   \n",
       "split5_test_recall                                                 0.85   \n",
       "split6_test_recall                                                 0.95   \n",
       "split7_test_recall                                                 0.45   \n",
       "split8_test_recall                                                 0.15   \n",
       "split9_test_recall                                                 0.45   \n",
       "mean_test_recall                                               0.598947   \n",
       "std_test_recall                                                0.271005   \n",
       "rank_test_recall                                                     28   \n",
       "split0_train_recall                                            0.649718   \n",
       "split1_train_recall                                             0.79096   \n",
       "split2_train_recall                                            0.649718   \n",
       "split3_train_recall                                             0.60452   \n",
       "split4_train_recall                                            0.642045   \n",
       "split5_train_recall                                               0.625   \n",
       "split6_train_recall                                            0.619318   \n",
       "split7_train_recall                                            0.664773   \n",
       "split8_train_recall                                            0.664773   \n",
       "split9_train_recall                                            0.659091   \n",
       "mean_train_recall                                              0.656992   \n",
       "std_train_recall                                               0.048578   \n",
       "\n",
       "                                                                     3   \\\n",
       "mean_fit_time                                                   1.07487   \n",
       "std_fit_time                                                   0.447706   \n",
       "mean_score_time                                                0.039542   \n",
       "std_score_time                                                 0.006445   \n",
       "param_class_weight                        {0: 1, 1: 2.0689655172413794}   \n",
       "params                  {'class_weight': {0: 1, 1: 2.0689655172413794}}   \n",
       "split0_test_precision                                               1.0   \n",
       "split1_test_precision                                           0.44186   \n",
       "split2_test_precision                                          0.583333   \n",
       "split3_test_precision                                               1.0   \n",
       "split4_test_precision                                               1.0   \n",
       "split5_test_precision                                          0.944444   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.833333   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                               1.0   \n",
       "mean_test_precision                                            0.880297   \n",
       "std_test_precision                                             0.193056   \n",
       "rank_test_precision                                                   1   \n",
       "split0_train_precision                                         0.770701   \n",
       "split1_train_precision                                          0.91875   \n",
       "split2_train_precision                                         0.834437   \n",
       "split3_train_precision                                         0.769737   \n",
       "split4_train_precision                                         0.786164   \n",
       "split5_train_precision                                         0.782051   \n",
       "split6_train_precision                                         0.769737   \n",
       "split7_train_precision                                         0.788462   \n",
       "split8_train_precision                                         0.787879   \n",
       "split9_train_precision                                         0.779874   \n",
       "mean_train_precision                                           0.798779   \n",
       "std_train_precision                                            0.043774   \n",
       "split0_test_recall                                             0.421053   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.736842   \n",
       "split3_test_recall                                             0.842105   \n",
       "split4_test_recall                                                  0.4   \n",
       "split5_test_recall                                                 0.85   \n",
       "split6_test_recall                                                 0.95   \n",
       "split7_test_recall                                                  0.5   \n",
       "split8_test_recall                                                 0.25   \n",
       "split9_test_recall                                                  0.6   \n",
       "mean_test_recall                                                  0.655   \n",
       "std_test_recall                                                0.244257   \n",
       "rank_test_recall                                                     27   \n",
       "split0_train_recall                                            0.683616   \n",
       "split1_train_recall                                            0.830508   \n",
       "split2_train_recall                                            0.711864   \n",
       "split3_train_recall                                            0.661017   \n",
       "split4_train_recall                                            0.710227   \n",
       "split5_train_recall                                            0.693182   \n",
       "split6_train_recall                                            0.664773   \n",
       "split7_train_recall                                            0.698864   \n",
       "split8_train_recall                                            0.738636   \n",
       "split9_train_recall                                            0.704545   \n",
       "mean_train_recall                                              0.709723   \n",
       "std_train_recall                                               0.045741   \n",
       "\n",
       "                                                                     4   \\\n",
       "mean_fit_time                                                  0.996487   \n",
       "std_fit_time                                                    0.39674   \n",
       "mean_score_time                                                0.071222   \n",
       "std_score_time                                                  0.05777   \n",
       "param_class_weight                        {0: 1, 1: 2.7586206896551726}   \n",
       "params                  {'class_weight': {0: 1, 1: 2.7586206896551726}}   \n",
       "split0_test_precision                                               1.0   \n",
       "split1_test_precision                                          0.431818   \n",
       "split2_test_precision                                          0.583333   \n",
       "split3_test_precision                                               1.0   \n",
       "split4_test_precision                                               1.0   \n",
       "split5_test_precision                                          0.944444   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.833333   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                          0.928571   \n",
       "mean_test_precision                                             0.87215   \n",
       "std_test_precision                                             0.192081   \n",
       "rank_test_precision                                                   6   \n",
       "split0_train_precision                                         0.776398   \n",
       "split1_train_precision                                         0.919753   \n",
       "split2_train_precision                                         0.845679   \n",
       "split3_train_precision                                          0.78125   \n",
       "split4_train_precision                                         0.792683   \n",
       "split5_train_precision                                         0.790123   \n",
       "split6_train_precision                                         0.779874   \n",
       "split7_train_precision                                              0.8   \n",
       "split8_train_precision                                         0.794118   \n",
       "split9_train_precision                                         0.787879   \n",
       "mean_train_precision                                           0.806776   \n",
       "std_train_precision                                             0.04197   \n",
       "split0_test_recall                                             0.473684   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.736842   \n",
       "split3_test_recall                                             0.842105   \n",
       "split4_test_recall                                                  0.4   \n",
       "split5_test_recall                                                 0.85   \n",
       "split6_test_recall                                                 0.95   \n",
       "split7_test_recall                                                  0.5   \n",
       "split8_test_recall                                                 0.25   \n",
       "split9_test_recall                                                 0.65   \n",
       "mean_test_recall                                               0.665263   \n",
       "std_test_recall                                                0.238894   \n",
       "rank_test_recall                                                     26   \n",
       "split0_train_recall                                            0.706215   \n",
       "split1_train_recall                                            0.841808   \n",
       "split2_train_recall                                            0.774011   \n",
       "split3_train_recall                                            0.706215   \n",
       "split4_train_recall                                            0.738636   \n",
       "split5_train_recall                                            0.727273   \n",
       "split6_train_recall                                            0.704545   \n",
       "split7_train_recall                                                0.75   \n",
       "split8_train_recall                                            0.767045   \n",
       "split9_train_recall                                            0.738636   \n",
       "mean_train_recall                                              0.745438   \n",
       "std_train_recall                                               0.039703   \n",
       "\n",
       "                                                                     5   \\\n",
       "mean_fit_time                                                  1.038066   \n",
       "std_fit_time                                                    0.56174   \n",
       "mean_score_time                                                0.041214   \n",
       "std_score_time                                                 0.010194   \n",
       "param_class_weight                        {0: 1, 1: 3.4482758620689657}   \n",
       "params                  {'class_weight': {0: 1, 1: 3.4482758620689657}}   \n",
       "split0_test_precision                                               1.0   \n",
       "split1_test_precision                                          0.431818   \n",
       "split2_test_precision                                          0.583333   \n",
       "split3_test_precision                                               1.0   \n",
       "split4_test_precision                                               1.0   \n",
       "split5_test_precision                                          0.944444   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.833333   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                          0.933333   \n",
       "mean_test_precision                                            0.872626   \n",
       "std_test_precision                                             0.192226   \n",
       "rank_test_precision                                                   4   \n",
       "split0_train_precision                                         0.784431   \n",
       "split1_train_precision                                         0.919753   \n",
       "split2_train_precision                                         0.850299   \n",
       "split3_train_precision                                         0.785276   \n",
       "split4_train_precision                                         0.796407   \n",
       "split5_train_precision                                         0.793939   \n",
       "split6_train_precision                                         0.785276   \n",
       "split7_train_precision                                         0.804734   \n",
       "split8_train_precision                                         0.797688   \n",
       "split9_train_precision                                         0.790419   \n",
       "mean_train_precision                                           0.810822   \n",
       "std_train_precision                                            0.040675   \n",
       "split0_test_recall                                             0.736842   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.736842   \n",
       "split3_test_recall                                             0.894737   \n",
       "split4_test_recall                                                 0.45   \n",
       "split5_test_recall                                                 0.85   \n",
       "split6_test_recall                                                 0.95   \n",
       "split7_test_recall                                                  0.5   \n",
       "split8_test_recall                                                  0.3   \n",
       "split9_test_recall                                                  0.7   \n",
       "mean_test_recall                                               0.711842   \n",
       "std_test_recall                                                0.218343   \n",
       "rank_test_recall                                                     25   \n",
       "split0_train_recall                                            0.740113   \n",
       "split1_train_recall                                            0.841808   \n",
       "split2_train_recall                                             0.80226   \n",
       "split3_train_recall                                            0.723164   \n",
       "split4_train_recall                                            0.755682   \n",
       "split5_train_recall                                            0.744318   \n",
       "split6_train_recall                                            0.727273   \n",
       "split7_train_recall                                            0.772727   \n",
       "split8_train_recall                                            0.784091   \n",
       "split9_train_recall                                                0.75   \n",
       "mean_train_recall                                              0.764144   \n",
       "std_train_recall                                               0.034982   \n",
       "\n",
       "                                                                    6   \\\n",
       "mean_fit_time                                                 0.923621   \n",
       "std_fit_time                                                  0.243622   \n",
       "mean_score_time                                                0.05615   \n",
       "std_score_time                                                0.063112   \n",
       "param_class_weight                        {0: 1, 1: 4.137931034482759}   \n",
       "params                  {'class_weight': {0: 1, 1: 4.137931034482759}}   \n",
       "split0_test_precision                                              1.0   \n",
       "split1_test_precision                                         0.431818   \n",
       "split2_test_precision                                         0.583333   \n",
       "split3_test_precision                                              1.0   \n",
       "split4_test_precision                                              1.0   \n",
       "split5_test_precision                                         0.944444   \n",
       "split6_test_precision                                              1.0   \n",
       "split7_test_precision                                         0.833333   \n",
       "split8_test_precision                                              1.0   \n",
       "split9_test_precision                                         0.933333   \n",
       "mean_test_precision                                           0.872626   \n",
       "std_test_precision                                            0.192226   \n",
       "rank_test_precision                                                  4   \n",
       "split0_train_precision                                        0.791667   \n",
       "split1_train_precision                                        0.914634   \n",
       "split2_train_precision                                        0.851429   \n",
       "split3_train_precision                                        0.792899   \n",
       "split4_train_precision                                        0.796512   \n",
       "split5_train_precision                                        0.802326   \n",
       "split6_train_precision                                        0.792899   \n",
       "split7_train_precision                                        0.807018   \n",
       "split8_train_precision                                             0.8   \n",
       "split9_train_precision                                        0.795322   \n",
       "mean_train_precision                                           0.81447   \n",
       "std_train_precision                                           0.037351   \n",
       "split0_test_recall                                            0.894737   \n",
       "split1_test_recall                                                 1.0   \n",
       "split2_test_recall                                            0.736842   \n",
       "split3_test_recall                                            0.894737   \n",
       "split4_test_recall                                                0.45   \n",
       "split5_test_recall                                                0.85   \n",
       "split6_test_recall                                                0.95   \n",
       "split7_test_recall                                                 0.5   \n",
       "split8_test_recall                                                0.35   \n",
       "split9_test_recall                                                 0.7   \n",
       "mean_test_recall                                              0.732632   \n",
       "std_test_recall                                               0.215999   \n",
       "rank_test_recall                                                    24   \n",
       "split0_train_recall                                           0.751412   \n",
       "split1_train_recall                                           0.847458   \n",
       "split2_train_recall                                           0.841808   \n",
       "split3_train_recall                                           0.757062   \n",
       "split4_train_recall                                           0.778409   \n",
       "split5_train_recall                                           0.784091   \n",
       "split6_train_recall                                           0.761364   \n",
       "split7_train_recall                                           0.784091   \n",
       "split8_train_recall                                           0.795455   \n",
       "split9_train_recall                                           0.772727   \n",
       "mean_train_recall                                             0.787388   \n",
       "std_train_recall                                              0.031374   \n",
       "\n",
       "                                                                    7   \\\n",
       "mean_fit_time                                                 1.042718   \n",
       "std_fit_time                                                  0.457954   \n",
       "mean_score_time                                               0.059822   \n",
       "std_score_time                                                0.030604   \n",
       "param_class_weight                        {0: 1, 1: 4.827586206896552}   \n",
       "params                  {'class_weight': {0: 1, 1: 4.827586206896552}}   \n",
       "split0_test_precision                                              1.0   \n",
       "split1_test_precision                                         0.431818   \n",
       "split2_test_precision                                         0.583333   \n",
       "split3_test_precision                                              1.0   \n",
       "split4_test_precision                                              1.0   \n",
       "split5_test_precision                                         0.944444   \n",
       "split6_test_precision                                              1.0   \n",
       "split7_test_precision                                         0.846154   \n",
       "split8_test_precision                                              1.0   \n",
       "split9_test_precision                                         0.941176   \n",
       "mean_test_precision                                           0.874693   \n",
       "std_test_precision                                             0.19226   \n",
       "rank_test_precision                                                  3   \n",
       "split0_train_precision                                         0.80226   \n",
       "split1_train_precision                                        0.915663   \n",
       "split2_train_precision                                        0.847458   \n",
       "split3_train_precision                                             0.8   \n",
       "split4_train_precision                                             0.8   \n",
       "split5_train_precision                                         0.80791   \n",
       "split6_train_precision                                             0.8   \n",
       "split7_train_precision                                        0.810345   \n",
       "split8_train_precision                                        0.804469   \n",
       "split9_train_precision                                        0.798851   \n",
       "mean_train_precision                                          0.818695   \n",
       "std_train_precision                                           0.035115   \n",
       "split0_test_recall                                            0.894737   \n",
       "split1_test_recall                                                 1.0   \n",
       "split2_test_recall                                            0.736842   \n",
       "split3_test_recall                                            0.894737   \n",
       "split4_test_recall                                                0.45   \n",
       "split5_test_recall                                                0.85   \n",
       "split6_test_recall                                                0.95   \n",
       "split7_test_recall                                                0.55   \n",
       "split8_test_recall                                                0.35   \n",
       "split9_test_recall                                                 0.8   \n",
       "mean_test_recall                                              0.747632   \n",
       "std_test_recall                                               0.211427   \n",
       "rank_test_recall                                                    23   \n",
       "split0_train_recall                                            0.80226   \n",
       "split1_train_recall                                           0.858757   \n",
       "split2_train_recall                                           0.847458   \n",
       "split3_train_recall                                            0.79096   \n",
       "split4_train_recall                                           0.795455   \n",
       "split5_train_recall                                             0.8125   \n",
       "split6_train_recall                                           0.795455   \n",
       "split7_train_recall                                           0.801136   \n",
       "split8_train_recall                                           0.818182   \n",
       "split9_train_recall                                           0.789773   \n",
       "mean_train_recall                                             0.811194   \n",
       "std_train_recall                                              0.022743   \n",
       "\n",
       "                                                                    8   \\\n",
       "mean_fit_time                                                 0.946644   \n",
       "std_fit_time                                                  0.283909   \n",
       "mean_score_time                                                0.04353   \n",
       "std_score_time                                                0.007929   \n",
       "param_class_weight                        {0: 1, 1: 5.517241379310345}   \n",
       "params                  {'class_weight': {0: 1, 1: 5.517241379310345}}   \n",
       "split0_test_precision                                              1.0   \n",
       "split1_test_precision                                         0.431818   \n",
       "split2_test_precision                                         0.583333   \n",
       "split3_test_precision                                              1.0   \n",
       "split4_test_precision                                              1.0   \n",
       "split5_test_precision                                         0.894737   \n",
       "split6_test_precision                                              1.0   \n",
       "split7_test_precision                                         0.857143   \n",
       "split8_test_precision                                              1.0   \n",
       "split9_test_precision                                         0.941176   \n",
       "mean_test_precision                                           0.870821   \n",
       "std_test_precision                                            0.190923   \n",
       "rank_test_precision                                                  7   \n",
       "split0_train_precision                                        0.804469   \n",
       "split1_train_precision                                        0.904762   \n",
       "split2_train_precision                                        0.842697   \n",
       "split3_train_precision                                        0.804469   \n",
       "split4_train_precision                                        0.802198   \n",
       "split5_train_precision                                        0.811111   \n",
       "split6_train_precision                                        0.798883   \n",
       "split7_train_precision                                          0.8125   \n",
       "split8_train_precision                                         0.80663   \n",
       "split9_train_precision                                        0.804469   \n",
       "mean_train_precision                                          0.819219   \n",
       "std_train_precision                                           0.030813   \n",
       "split0_test_recall                                            0.894737   \n",
       "split1_test_recall                                                 1.0   \n",
       "split2_test_recall                                            0.736842   \n",
       "split3_test_recall                                            0.947368   \n",
       "split4_test_recall                                                 0.5   \n",
       "split5_test_recall                                                0.85   \n",
       "split6_test_recall                                                 1.0   \n",
       "split7_test_recall                                                 0.6   \n",
       "split8_test_recall                                                0.35   \n",
       "split9_test_recall                                                 0.8   \n",
       "mean_test_recall                                              0.767895   \n",
       "std_test_recall                                               0.209612   \n",
       "rank_test_recall                                                    22   \n",
       "split0_train_recall                                           0.813559   \n",
       "split1_train_recall                                           0.858757   \n",
       "split2_train_recall                                           0.847458   \n",
       "split3_train_recall                                           0.813559   \n",
       "split4_train_recall                                           0.829545   \n",
       "split5_train_recall                                           0.829545   \n",
       "split6_train_recall                                             0.8125   \n",
       "split7_train_recall                                             0.8125   \n",
       "split8_train_recall                                           0.829545   \n",
       "split9_train_recall                                           0.818182   \n",
       "mean_train_recall                                             0.826515   \n",
       "std_train_recall                                              0.015178   \n",
       "\n",
       "                                                                    9   ...  \\\n",
       "mean_fit_time                                                 0.954515  ...   \n",
       "std_fit_time                                                  0.168779  ...   \n",
       "mean_score_time                                               0.044313  ...   \n",
       "std_score_time                                                0.007577  ...   \n",
       "param_class_weight                        {0: 1, 1: 6.206896551724139}  ...   \n",
       "params                  {'class_weight': {0: 1, 1: 6.206896551724139}}  ...   \n",
       "split0_test_precision                                              1.0  ...   \n",
       "split1_test_precision                                         0.422222  ...   \n",
       "split2_test_precision                                         0.583333  ...   \n",
       "split3_test_precision                                         0.947368  ...   \n",
       "split4_test_precision                                              1.0  ...   \n",
       "split5_test_precision                                         0.894737  ...   \n",
       "split6_test_precision                                              1.0  ...   \n",
       "split7_test_precision                                            0.875  ...   \n",
       "split8_test_precision                                              1.0  ...   \n",
       "split9_test_precision                                         0.941176  ...   \n",
       "mean_test_precision                                           0.866384  ...   \n",
       "std_test_precision                                            0.190221  ...   \n",
       "rank_test_precision                                                  8  ...   \n",
       "split0_train_precision                                         0.80663  ...   \n",
       "split1_train_precision                                        0.910714  ...   \n",
       "split2_train_precision                                        0.842697  ...   \n",
       "split3_train_precision                                        0.807692  ...   \n",
       "split4_train_precision                                        0.805405  ...   \n",
       "split5_train_precision                                        0.807692  ...   \n",
       "split6_train_precision                                             0.8  ...   \n",
       "split7_train_precision                                        0.815642  ...   \n",
       "split8_train_precision                                        0.807487  ...   \n",
       "split9_train_precision                                        0.807692  ...   \n",
       "mean_train_precision                                          0.821165  ...   \n",
       "std_train_precision                                           0.031863  ...   \n",
       "split0_test_recall                                            0.894737  ...   \n",
       "split1_test_recall                                                 1.0  ...   \n",
       "split2_test_recall                                            0.736842  ...   \n",
       "split3_test_recall                                            0.947368  ...   \n",
       "split4_test_recall                                                 0.5  ...   \n",
       "split5_test_recall                                                0.85  ...   \n",
       "split6_test_recall                                                 1.0  ...   \n",
       "split7_test_recall                                                 0.7  ...   \n",
       "split8_test_recall                                                0.45  ...   \n",
       "split9_test_recall                                                 0.8  ...   \n",
       "mean_test_recall                                              0.787895  ...   \n",
       "std_test_recall                                               0.183907  ...   \n",
       "rank_test_recall                                                    21  ...   \n",
       "split0_train_recall                                           0.824859  ...   \n",
       "split1_train_recall                                           0.864407  ...   \n",
       "split2_train_recall                                           0.847458  ...   \n",
       "split3_train_recall                                           0.830508  ...   \n",
       "split4_train_recall                                           0.846591  ...   \n",
       "split5_train_recall                                           0.835227  ...   \n",
       "split6_train_recall                                           0.818182  ...   \n",
       "split7_train_recall                                           0.829545  ...   \n",
       "split8_train_recall                                           0.857955  ...   \n",
       "split9_train_recall                                           0.835227  ...   \n",
       "mean_train_recall                                             0.838996  ...   \n",
       "std_train_recall                                               0.01399  ...   \n",
       "\n",
       "                                                                     20  \\\n",
       "mean_fit_time                                                  1.358662   \n",
       "std_fit_time                                                   0.427797   \n",
       "mean_score_time                                                0.045166   \n",
       "std_score_time                                                 0.006795   \n",
       "param_class_weight                        {0: 1, 1: 13.793103448275863}   \n",
       "params                  {'class_weight': {0: 1, 1: 13.793103448275863}}   \n",
       "split0_test_precision                                          0.818182   \n",
       "split1_test_precision                                          0.404255   \n",
       "split2_test_precision                                          0.576923   \n",
       "split3_test_precision                                          0.947368   \n",
       "split4_test_precision                                               1.0   \n",
       "split5_test_precision                                          0.857143   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.882353   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                          0.941176   \n",
       "mean_test_precision                                             0.84274   \n",
       "std_test_precision                                             0.189773   \n",
       "rank_test_precision                                                  19   \n",
       "split0_train_precision                                         0.803191   \n",
       "split1_train_precision                                         0.865169   \n",
       "split2_train_precision                                         0.816754   \n",
       "split3_train_precision                                         0.794737   \n",
       "split4_train_precision                                         0.796875   \n",
       "split5_train_precision                                         0.798942   \n",
       "split6_train_precision                                          0.78836   \n",
       "split7_train_precision                                         0.792746   \n",
       "split8_train_precision                                         0.790816   \n",
       "split9_train_precision                                         0.795812   \n",
       "mean_train_precision                                            0.80434   \n",
       "std_train_precision                                            0.021629   \n",
       "split0_test_recall                                             0.947368   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.789474   \n",
       "split3_test_recall                                             0.947368   \n",
       "split4_test_recall                                                  0.6   \n",
       "split5_test_recall                                                  0.9   \n",
       "split6_test_recall                                                  1.0   \n",
       "split7_test_recall                                                 0.75   \n",
       "split8_test_recall                                                 0.65   \n",
       "split9_test_recall                                                  0.8   \n",
       "mean_test_recall                                               0.838421   \n",
       "std_test_recall                                                0.135567   \n",
       "rank_test_recall                                                      4   \n",
       "split0_train_recall                                            0.853107   \n",
       "split1_train_recall                                            0.870056   \n",
       "split2_train_recall                                            0.881356   \n",
       "split3_train_recall                                            0.853107   \n",
       "split4_train_recall                                            0.869318   \n",
       "split5_train_recall                                            0.857955   \n",
       "split6_train_recall                                            0.846591   \n",
       "split7_train_recall                                            0.869318   \n",
       "split8_train_recall                                            0.880682   \n",
       "split9_train_recall                                            0.863636   \n",
       "mean_train_recall                                              0.864513   \n",
       "std_train_recall                                               0.011168   \n",
       "\n",
       "                                                                     21  \\\n",
       "mean_fit_time                                                  1.231279   \n",
       "std_fit_time                                                   0.487817   \n",
       "mean_score_time                                                  0.0427   \n",
       "std_score_time                                                 0.009966   \n",
       "param_class_weight                        {0: 1, 1: 14.482758620689657}   \n",
       "params                  {'class_weight': {0: 1, 1: 14.482758620689657}}   \n",
       "split0_test_precision                                          0.818182   \n",
       "split1_test_precision                                          0.404255   \n",
       "split2_test_precision                                          0.576923   \n",
       "split3_test_precision                                          0.947368   \n",
       "split4_test_precision                                               1.0   \n",
       "split5_test_precision                                          0.857143   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.882353   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                          0.888889   \n",
       "mean_test_precision                                            0.837511   \n",
       "std_test_precision                                             0.187697   \n",
       "rank_test_precision                                                  20   \n",
       "split0_train_precision                                         0.804233   \n",
       "split1_train_precision                                         0.860335   \n",
       "split2_train_precision                                         0.795918   \n",
       "split3_train_precision                                         0.787565   \n",
       "split4_train_precision                                         0.797927   \n",
       "split5_train_precision                                         0.794737   \n",
       "split6_train_precision                                         0.789474   \n",
       "split7_train_precision                                          0.78866   \n",
       "split8_train_precision                                         0.791878   \n",
       "split9_train_precision                                         0.795812   \n",
       "mean_train_precision                                           0.800654   \n",
       "std_train_precision                                            0.020445   \n",
       "split0_test_recall                                             0.947368   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.789474   \n",
       "split3_test_recall                                             0.947368   \n",
       "split4_test_recall                                                  0.6   \n",
       "split5_test_recall                                                  0.9   \n",
       "split6_test_recall                                                  1.0   \n",
       "split7_test_recall                                                 0.75   \n",
       "split8_test_recall                                                 0.65   \n",
       "split9_test_recall                                                  0.8   \n",
       "mean_test_recall                                               0.838421   \n",
       "std_test_recall                                                0.135567   \n",
       "rank_test_recall                                                      4   \n",
       "split0_train_recall                                            0.858757   \n",
       "split1_train_recall                                            0.870056   \n",
       "split2_train_recall                                            0.881356   \n",
       "split3_train_recall                                            0.858757   \n",
       "split4_train_recall                                               0.875   \n",
       "split5_train_recall                                            0.857955   \n",
       "split6_train_recall                                            0.852273   \n",
       "split7_train_recall                                            0.869318   \n",
       "split8_train_recall                                            0.886364   \n",
       "split9_train_recall                                            0.863636   \n",
       "mean_train_recall                                              0.867347   \n",
       "std_train_recall                                               0.010509   \n",
       "\n",
       "                                                                     22  \\\n",
       "mean_fit_time                                                  1.412879   \n",
       "std_fit_time                                                   0.385397   \n",
       "mean_score_time                                                0.098305   \n",
       "std_score_time                                                 0.123807   \n",
       "param_class_weight                        {0: 1, 1: 15.172413793103448}   \n",
       "params                  {'class_weight': {0: 1, 1: 15.172413793103448}}   \n",
       "split0_test_precision                                          0.818182   \n",
       "split1_test_precision                                              0.38   \n",
       "split2_test_precision                                          0.576923   \n",
       "split3_test_precision                                          0.947368   \n",
       "split4_test_precision                                               1.0   \n",
       "split5_test_precision                                          0.857143   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.882353   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                          0.888889   \n",
       "mean_test_precision                                            0.835086   \n",
       "std_test_precision                                             0.193352   \n",
       "rank_test_precision                                                  21   \n",
       "split0_train_precision                                              0.8   \n",
       "split1_train_precision                                         0.850829   \n",
       "split2_train_precision                                         0.795918   \n",
       "split3_train_precision                                         0.795812   \n",
       "split4_train_precision                                         0.793814   \n",
       "split5_train_precision                                         0.795812   \n",
       "split6_train_precision                                         0.777202   \n",
       "split7_train_precision                                         0.784615   \n",
       "split8_train_precision                                          0.78392   \n",
       "split9_train_precision                                         0.795812   \n",
       "mean_train_precision                                           0.797373   \n",
       "std_train_precision                                            0.019071   \n",
       "split0_test_recall                                             0.947368   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.789474   \n",
       "split3_test_recall                                             0.947368   \n",
       "split4_test_recall                                                  0.6   \n",
       "split5_test_recall                                                  0.9   \n",
       "split6_test_recall                                                  1.0   \n",
       "split7_test_recall                                                 0.75   \n",
       "split8_test_recall                                                 0.65   \n",
       "split9_test_recall                                                  0.8   \n",
       "mean_test_recall                                               0.838421   \n",
       "std_test_recall                                                0.135567   \n",
       "rank_test_recall                                                      4   \n",
       "split0_train_recall                                            0.858757   \n",
       "split1_train_recall                                            0.870056   \n",
       "split2_train_recall                                            0.881356   \n",
       "split3_train_recall                                            0.858757   \n",
       "split4_train_recall                                               0.875   \n",
       "split5_train_recall                                            0.863636   \n",
       "split6_train_recall                                            0.852273   \n",
       "split7_train_recall                                            0.869318   \n",
       "split8_train_recall                                            0.886364   \n",
       "split9_train_recall                                            0.863636   \n",
       "mean_train_recall                                              0.867915   \n",
       "std_train_recall                                               0.010133   \n",
       "\n",
       "                                                                     23  \\\n",
       "mean_fit_time                                                  1.265294   \n",
       "std_fit_time                                                   0.404825   \n",
       "mean_score_time                                                0.036948   \n",
       "std_score_time                                                 0.005303   \n",
       "param_class_weight                        {0: 1, 1: 15.862068965517242}   \n",
       "params                  {'class_weight': {0: 1, 1: 15.862068965517242}}   \n",
       "split0_test_precision                                          0.782609   \n",
       "split1_test_precision                                          0.365385   \n",
       "split2_test_precision                                          0.555556   \n",
       "split3_test_precision                                          0.947368   \n",
       "split4_test_precision                                          0.923077   \n",
       "split5_test_precision                                          0.857143   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.882353   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                          0.842105   \n",
       "mean_test_precision                                             0.81556   \n",
       "std_test_precision                                             0.193704   \n",
       "rank_test_precision                                                  22   \n",
       "split0_train_precision                                              0.8   \n",
       "split1_train_precision                                         0.827957   \n",
       "split2_train_precision                                         0.791878   \n",
       "split3_train_precision                                         0.787565   \n",
       "split4_train_precision                                         0.789744   \n",
       "split5_train_precision                                         0.795812   \n",
       "split6_train_precision                                         0.777202   \n",
       "split7_train_precision                                          0.78866   \n",
       "split8_train_precision                                          0.78392   \n",
       "split9_train_precision                                         0.797927   \n",
       "mean_train_precision                                           0.794066   \n",
       "std_train_precision                                            0.012977   \n",
       "split0_test_recall                                             0.947368   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.789474   \n",
       "split3_test_recall                                             0.947368   \n",
       "split4_test_recall                                                  0.6   \n",
       "split5_test_recall                                                  0.9   \n",
       "split6_test_recall                                                  1.0   \n",
       "split7_test_recall                                                 0.75   \n",
       "split8_test_recall                                                 0.65   \n",
       "split9_test_recall                                                  0.8   \n",
       "mean_test_recall                                               0.838421   \n",
       "std_test_recall                                                0.135567   \n",
       "rank_test_recall                                                      4   \n",
       "split0_train_recall                                            0.858757   \n",
       "split1_train_recall                                            0.870056   \n",
       "split2_train_recall                                            0.881356   \n",
       "split3_train_recall                                            0.858757   \n",
       "split4_train_recall                                               0.875   \n",
       "split5_train_recall                                            0.863636   \n",
       "split6_train_recall                                            0.852273   \n",
       "split7_train_recall                                            0.869318   \n",
       "split8_train_recall                                            0.886364   \n",
       "split9_train_recall                                               0.875   \n",
       "mean_train_recall                                              0.869052   \n",
       "std_train_recall                                               0.010226   \n",
       "\n",
       "                                                                     24  \\\n",
       "mean_fit_time                                                  1.296301   \n",
       "std_fit_time                                                    0.39978   \n",
       "mean_score_time                                                0.042273   \n",
       "std_score_time                                                 0.007038   \n",
       "param_class_weight                        {0: 1, 1: 16.551724137931036}   \n",
       "params                  {'class_weight': {0: 1, 1: 16.551724137931036}}   \n",
       "split0_test_precision                                          0.782609   \n",
       "split1_test_precision                                          0.372549   \n",
       "split2_test_precision                                          0.555556   \n",
       "split3_test_precision                                          0.947368   \n",
       "split4_test_precision                                          0.923077   \n",
       "split5_test_precision                                          0.857143   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.833333   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                          0.842105   \n",
       "mean_test_precision                                            0.811374   \n",
       "std_test_precision                                             0.190916   \n",
       "rank_test_precision                                                  23   \n",
       "split0_train_precision                                         0.795812   \n",
       "split1_train_precision                                         0.832432   \n",
       "split2_train_precision                                         0.787879   \n",
       "split3_train_precision                                         0.787565   \n",
       "split4_train_precision                                         0.789744   \n",
       "split5_train_precision                                         0.791667   \n",
       "split6_train_precision                                         0.773196   \n",
       "split7_train_precision                                         0.784615   \n",
       "split8_train_precision                                          0.78392   \n",
       "split9_train_precision                                          0.78866   \n",
       "mean_train_precision                                           0.791549   \n",
       "std_train_precision                                            0.014744   \n",
       "split0_test_recall                                             0.947368   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.789474   \n",
       "split3_test_recall                                             0.947368   \n",
       "split4_test_recall                                                  0.6   \n",
       "split5_test_recall                                                  0.9   \n",
       "split6_test_recall                                                  1.0   \n",
       "split7_test_recall                                                 0.75   \n",
       "split8_test_recall                                                 0.65   \n",
       "split9_test_recall                                                  0.8   \n",
       "mean_test_recall                                               0.838421   \n",
       "std_test_recall                                                0.135567   \n",
       "rank_test_recall                                                      4   \n",
       "split0_train_recall                                            0.858757   \n",
       "split1_train_recall                                            0.870056   \n",
       "split2_train_recall                                            0.881356   \n",
       "split3_train_recall                                            0.858757   \n",
       "split4_train_recall                                               0.875   \n",
       "split5_train_recall                                            0.863636   \n",
       "split6_train_recall                                            0.852273   \n",
       "split7_train_recall                                            0.869318   \n",
       "split8_train_recall                                            0.886364   \n",
       "split9_train_recall                                            0.869318   \n",
       "mean_train_recall                                              0.868484   \n",
       "std_train_recall                                               0.010036   \n",
       "\n",
       "                                                                    25  \\\n",
       "mean_fit_time                                                 1.420746   \n",
       "std_fit_time                                                   0.57186   \n",
       "mean_score_time                                               0.079623   \n",
       "std_score_time                                                0.092874   \n",
       "param_class_weight                        {0: 1, 1: 17.24137931034483}   \n",
       "params                  {'class_weight': {0: 1, 1: 17.24137931034483}}   \n",
       "split0_test_precision                                         0.782609   \n",
       "split1_test_precision                                         0.372549   \n",
       "split2_test_precision                                         0.555556   \n",
       "split3_test_precision                                         0.947368   \n",
       "split4_test_precision                                         0.923077   \n",
       "split5_test_precision                                         0.818182   \n",
       "split6_test_precision                                              1.0   \n",
       "split7_test_precision                                         0.789474   \n",
       "split8_test_precision                                              1.0   \n",
       "split9_test_precision                                         0.842105   \n",
       "mean_test_precision                                           0.803092   \n",
       "std_test_precision                                            0.190198   \n",
       "rank_test_precision                                                 24   \n",
       "split0_train_precision                                        0.791667   \n",
       "split1_train_precision                                        0.814815   \n",
       "split2_train_precision                                            0.78   \n",
       "split3_train_precision                                         0.78866   \n",
       "split4_train_precision                                        0.773869   \n",
       "split5_train_precision                                        0.791667   \n",
       "split6_train_precision                                        0.769231   \n",
       "split7_train_precision                                        0.780612   \n",
       "split8_train_precision                                         0.78392   \n",
       "split9_train_precision                                        0.789744   \n",
       "mean_train_precision                                          0.786418   \n",
       "std_train_precision                                           0.011881   \n",
       "split0_test_recall                                            0.947368   \n",
       "split1_test_recall                                                 1.0   \n",
       "split2_test_recall                                            0.789474   \n",
       "split3_test_recall                                            0.947368   \n",
       "split4_test_recall                                                 0.6   \n",
       "split5_test_recall                                                 0.9   \n",
       "split6_test_recall                                                 1.0   \n",
       "split7_test_recall                                                0.75   \n",
       "split8_test_recall                                                0.65   \n",
       "split9_test_recall                                                 0.8   \n",
       "mean_test_recall                                              0.838421   \n",
       "std_test_recall                                               0.135567   \n",
       "rank_test_recall                                                     4   \n",
       "split0_train_recall                                           0.858757   \n",
       "split1_train_recall                                           0.870056   \n",
       "split2_train_recall                                           0.881356   \n",
       "split3_train_recall                                           0.864407   \n",
       "split4_train_recall                                              0.875   \n",
       "split5_train_recall                                           0.863636   \n",
       "split6_train_recall                                           0.852273   \n",
       "split7_train_recall                                           0.869318   \n",
       "split8_train_recall                                           0.886364   \n",
       "split9_train_recall                                              0.875   \n",
       "mean_train_recall                                             0.869617   \n",
       "std_train_recall                                              0.009789   \n",
       "\n",
       "                                                                     26  \\\n",
       "mean_fit_time                                                  1.365398   \n",
       "std_fit_time                                                   0.562338   \n",
       "mean_score_time                                                0.044323   \n",
       "std_score_time                                                 0.005111   \n",
       "param_class_weight                        {0: 1, 1: 17.931034482758623}   \n",
       "params                  {'class_weight': {0: 1, 1: 17.931034482758623}}   \n",
       "split0_test_precision                                          0.782609   \n",
       "split1_test_precision                                          0.358491   \n",
       "split2_test_precision                                          0.535714   \n",
       "split3_test_precision                                          0.947368   \n",
       "split4_test_precision                                          0.923077   \n",
       "split5_test_precision                                          0.818182   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.789474   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                               0.8   \n",
       "mean_test_precision                                            0.795491   \n",
       "std_test_precision                                             0.195495   \n",
       "rank_test_precision                                                  25   \n",
       "split0_train_precision                                         0.791667   \n",
       "split1_train_precision                                         0.810526   \n",
       "split2_train_precision                                         0.772277   \n",
       "split3_train_precision                                          0.77665   \n",
       "split4_train_precision                                         0.773869   \n",
       "split5_train_precision                                         0.791667   \n",
       "split6_train_precision                                         0.765306   \n",
       "split7_train_precision                                         0.780612   \n",
       "split8_train_precision                                            0.785   \n",
       "split9_train_precision                                         0.789744   \n",
       "mean_train_precision                                           0.783732   \n",
       "std_train_precision                                            0.012286   \n",
       "split0_test_recall                                             0.947368   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.789474   \n",
       "split3_test_recall                                             0.947368   \n",
       "split4_test_recall                                                  0.6   \n",
       "split5_test_recall                                                  0.9   \n",
       "split6_test_recall                                                  1.0   \n",
       "split7_test_recall                                                 0.75   \n",
       "split8_test_recall                                                 0.65   \n",
       "split9_test_recall                                                  0.8   \n",
       "mean_test_recall                                               0.838421   \n",
       "std_test_recall                                                0.135567   \n",
       "rank_test_recall                                                      4   \n",
       "split0_train_recall                                            0.858757   \n",
       "split1_train_recall                                            0.870056   \n",
       "split2_train_recall                                            0.881356   \n",
       "split3_train_recall                                            0.864407   \n",
       "split4_train_recall                                               0.875   \n",
       "split5_train_recall                                            0.863636   \n",
       "split6_train_recall                                            0.852273   \n",
       "split7_train_recall                                            0.869318   \n",
       "split8_train_recall                                            0.892045   \n",
       "split9_train_recall                                               0.875   \n",
       "mean_train_recall                                              0.870185   \n",
       "std_train_recall                                               0.010851   \n",
       "\n",
       "                                                                     27  \\\n",
       "mean_fit_time                                                  1.522262   \n",
       "std_fit_time                                                   0.490938   \n",
       "mean_score_time                                                 0.06233   \n",
       "std_score_time                                                 0.027572   \n",
       "param_class_weight                        {0: 1, 1: 18.620689655172416}   \n",
       "params                  {'class_weight': {0: 1, 1: 18.620689655172416}}   \n",
       "split0_test_precision                                          0.782609   \n",
       "split1_test_precision                                          0.345455   \n",
       "split2_test_precision                                          0.535714   \n",
       "split3_test_precision                                          0.947368   \n",
       "split4_test_precision                                          0.866667   \n",
       "split5_test_precision                                          0.818182   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                          0.789474   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                               0.8   \n",
       "mean_test_precision                                            0.788547   \n",
       "std_test_precision                                             0.195462   \n",
       "rank_test_precision                                                  26   \n",
       "split0_train_precision                                         0.791667   \n",
       "split1_train_precision                                         0.806283   \n",
       "split2_train_precision                                         0.764706   \n",
       "split3_train_precision                                         0.772727   \n",
       "split4_train_precision                                         0.762376   \n",
       "split5_train_precision                                         0.792746   \n",
       "split6_train_precision                                         0.762626   \n",
       "split7_train_precision                                         0.768844   \n",
       "split8_train_precision                                          0.78607   \n",
       "split9_train_precision                                         0.781726   \n",
       "mean_train_precision                                           0.778977   \n",
       "std_train_precision                                            0.014291   \n",
       "split0_test_recall                                             0.947368   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.789474   \n",
       "split3_test_recall                                             0.947368   \n",
       "split4_test_recall                                                 0.65   \n",
       "split5_test_recall                                                  0.9   \n",
       "split6_test_recall                                                  1.0   \n",
       "split7_test_recall                                                 0.75   \n",
       "split8_test_recall                                                 0.65   \n",
       "split9_test_recall                                                  0.8   \n",
       "mean_test_recall                                               0.843421   \n",
       "std_test_recall                                                0.127355   \n",
       "rank_test_recall                                                      1   \n",
       "split0_train_recall                                            0.858757   \n",
       "split1_train_recall                                            0.870056   \n",
       "split2_train_recall                                            0.881356   \n",
       "split3_train_recall                                            0.864407   \n",
       "split4_train_recall                                               0.875   \n",
       "split5_train_recall                                            0.869318   \n",
       "split6_train_recall                                            0.857955   \n",
       "split7_train_recall                                            0.869318   \n",
       "split8_train_recall                                            0.897727   \n",
       "split9_train_recall                                               0.875   \n",
       "mean_train_recall                                              0.871889   \n",
       "std_train_recall                                               0.011026   \n",
       "\n",
       "                                                                     28  \\\n",
       "mean_fit_time                                                  1.359854   \n",
       "std_fit_time                                                   0.365732   \n",
       "mean_score_time                                                0.045622   \n",
       "std_score_time                                                 0.014369   \n",
       "param_class_weight                        {0: 1, 1: 19.310344827586206}   \n",
       "params                  {'class_weight': {0: 1, 1: 19.310344827586206}}   \n",
       "split0_test_precision                                          0.782609   \n",
       "split1_test_precision                                          0.339286   \n",
       "split2_test_precision                                          0.535714   \n",
       "split3_test_precision                                          0.947368   \n",
       "split4_test_precision                                          0.866667   \n",
       "split5_test_precision                                          0.818182   \n",
       "split6_test_precision                                               1.0   \n",
       "split7_test_precision                                              0.75   \n",
       "split8_test_precision                                               1.0   \n",
       "split9_test_precision                                               0.8   \n",
       "mean_test_precision                                            0.783983   \n",
       "std_test_precision                                             0.197189   \n",
       "rank_test_precision                                                  28   \n",
       "split0_train_precision                                          0.78866   \n",
       "split1_train_precision                                         0.802083   \n",
       "split2_train_precision                                         0.760976   \n",
       "split3_train_precision                                         0.772727   \n",
       "split4_train_precision                                         0.754902   \n",
       "split5_train_precision                                         0.789744   \n",
       "split6_train_precision                                         0.747525   \n",
       "split7_train_precision                                         0.753695   \n",
       "split8_train_precision                                         0.781095   \n",
       "split9_train_precision                                         0.777778   \n",
       "mean_train_precision                                           0.772918   \n",
       "std_train_precision                                            0.017186   \n",
       "split0_test_recall                                             0.947368   \n",
       "split1_test_recall                                                  1.0   \n",
       "split2_test_recall                                             0.789474   \n",
       "split3_test_recall                                             0.947368   \n",
       "split4_test_recall                                                 0.65   \n",
       "split5_test_recall                                                  0.9   \n",
       "split6_test_recall                                                  1.0   \n",
       "split7_test_recall                                                 0.75   \n",
       "split8_test_recall                                                 0.65   \n",
       "split9_test_recall                                                  0.8   \n",
       "mean_test_recall                                               0.843421   \n",
       "std_test_recall                                                0.127355   \n",
       "rank_test_recall                                                      1   \n",
       "split0_train_recall                                            0.864407   \n",
       "split1_train_recall                                            0.870056   \n",
       "split2_train_recall                                            0.881356   \n",
       "split3_train_recall                                            0.864407   \n",
       "split4_train_recall                                               0.875   \n",
       "split5_train_recall                                               0.875   \n",
       "split6_train_recall                                            0.857955   \n",
       "split7_train_recall                                            0.869318   \n",
       "split8_train_recall                                            0.892045   \n",
       "split9_train_recall                                               0.875   \n",
       "mean_train_recall                                              0.872454   \n",
       "std_train_recall                                               0.009153   \n",
       "\n",
       "                                                       29  \n",
       "mean_fit_time                                     1.10281  \n",
       "std_fit_time                                     0.222626  \n",
       "mean_score_time                                  0.028376  \n",
       "std_score_time                                   0.011769  \n",
       "param_class_weight                        {0: 1, 1: 20.0}  \n",
       "params                  {'class_weight': {0: 1, 1: 20.0}}  \n",
       "split0_test_precision                                0.75  \n",
       "split1_test_precision                            0.333333  \n",
       "split2_test_precision                            0.535714  \n",
       "split3_test_precision                            0.947368  \n",
       "split4_test_precision                            0.866667  \n",
       "split5_test_precision                            0.818182  \n",
       "split6_test_precision                                 1.0  \n",
       "split7_test_precision                            0.714286  \n",
       "split8_test_precision                                 1.0  \n",
       "split9_test_precision                                 0.8  \n",
       "mean_test_precision                              0.776555  \n",
       "std_test_precision                               0.199616  \n",
       "rank_test_precision                                    29  \n",
       "split0_train_precision                           0.780612  \n",
       "split1_train_precision                           0.789744  \n",
       "split2_train_precision                           0.764706  \n",
       "split3_train_precision                           0.768844  \n",
       "split4_train_precision                           0.754902  \n",
       "split5_train_precision                           0.785714  \n",
       "split6_train_precision                           0.740196  \n",
       "split7_train_precision                           0.758621  \n",
       "split8_train_precision                           0.782178  \n",
       "split9_train_precision                           0.777778  \n",
       "mean_train_precision                             0.770329  \n",
       "std_train_precision                               0.01494  \n",
       "split0_test_recall                               0.947368  \n",
       "split1_test_recall                                    1.0  \n",
       "split2_test_recall                               0.789474  \n",
       "split3_test_recall                               0.947368  \n",
       "split4_test_recall                                   0.65  \n",
       "split5_test_recall                                    0.9  \n",
       "split6_test_recall                                    1.0  \n",
       "split7_test_recall                                   0.75  \n",
       "split8_test_recall                                   0.65  \n",
       "split9_test_recall                                    0.8  \n",
       "mean_test_recall                                 0.843421  \n",
       "std_test_recall                                  0.127355  \n",
       "rank_test_recall                                        1  \n",
       "split0_train_recall                              0.864407  \n",
       "split1_train_recall                              0.870056  \n",
       "split2_train_recall                              0.881356  \n",
       "split3_train_recall                              0.864407  \n",
       "split4_train_recall                                 0.875  \n",
       "split5_train_recall                                 0.875  \n",
       "split6_train_recall                              0.857955  \n",
       "split7_train_recall                                 0.875  \n",
       "split8_train_recall                              0.897727  \n",
       "split9_train_recall                                 0.875  \n",
       "mean_train_recall                                0.873591  \n",
       "std_train_recall                                 0.010375  \n",
       "\n",
       "[56 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.DataFrame(grid.cv_results_)\n",
    "df_new.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5233fe6-8004-484c-9e7b-d8185d2c7198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize  =(12,4))\n",
    "for score in ['mean_test_recall','mean_test_precision'] : \n",
    "    plt.plot([ _[1] for _ in df_new['param_class_weight']], \n",
    "            df_new[score] ,\n",
    "            label = score)\n",
    "plt.legend() ; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d63ad25-1215-453a-be05-99532d0a6e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: np.float64(0.0)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(0.6896551724137931)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(1.3793103448275863)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.0689655172413794)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.7586206896551726)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(3.4482758620689657)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(4.13793103448...\n",
       "                                           1: np.float64(17.931034482758623)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(18.620689655172416)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(19.310344827586206)},\n",
       "                                          {0: 1, 1: np.float64(20.0)}]},\n",
       "             refit=&#x27;both_min&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;both_min&#x27;: make_scorer(min_both, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [{0: 1, 1: np.float64(0.0)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(0.6896551724137931)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(1.3793103448275863)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.0689655172413794)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.7586206896551726)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(3.4482758620689657)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(4.13793103448...\n",
       "                                           1: np.float64(17.931034482758623)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(18.620689655172416)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(19.310344827586206)},\n",
       "                                          {0: 1, 1: np.float64(20.0)}]},\n",
       "             refit=&#x27;both_min&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;both_min&#x27;: make_scorer(min_both, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;precision&#x27;: make_scorer(precision_score, response_method=&#x27;predict&#x27;),\n",
       "                      &#x27;recall&#x27;: make_scorer(recall_score, response_method=&#x27;predict&#x27;)})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight={0: 1, 1: np.float64(15.862068965517242)},\n",
       "                   max_iter=1000)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight={0: 1, 1: np.float64(15.862068965517242)},\n",
       "                   max_iter=1000)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 1, 1: np.float64(0.0)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(0.6896551724137931)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(1.3793103448275863)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.0689655172413794)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(2.7586206896551726)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(3.4482758620689657)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(4.13793103448...\n",
       "                                           1: np.float64(17.931034482758623)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(18.620689655172416)},\n",
       "                                          {0: 1,\n",
       "                                           1: np.float64(19.310344827586206)},\n",
       "                                          {0: 1, 1: np.float64(20.0)}]},\n",
       "             refit='both_min', return_train_score=True,\n",
       "             scoring={'both_min': make_scorer(min_both, response_method='predict'),\n",
       "                      'precision': make_scorer(precision_score, response_method='predict'),\n",
       "                      'recall': make_scorer(recall_score, response_method='predict')})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a custom testing parameter min(precision,recall)\n",
    "def min_both(y_true ,y_pred) : \n",
    "    recall = recall_score(y_true,y_pred)\n",
    "    precision = precision_score(y_true,y_pred)\n",
    "    return min(recall,precision)\n",
    "#since now we have our custom parameter we revaluate our custom model so that we can get the logistics regression going good\n",
    "grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter = 1000), \n",
    "    param_grid ={ 'class_weight'  :[{0:1,1:v} for v in np.linspace(0,20,30)]},\n",
    "    scoring = {'precision':make_scorer(precision_score) ,'recall' : make_scorer(recall_score),'both_min' : make_scorer(min_both)}, \n",
    "    refit = 'both_min',\n",
    "    return_train_score = True,\n",
    "    cv  = 5,\n",
    "    n_jobs = -1\n",
    ")\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1f203f1-c06c-484e-b815-9c6ce67f37c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_both_min</th>\n",
       "      <th>std_test_both_min</th>\n",
       "      <th>rank_test_both_min</th>\n",
       "      <th>split0_train_both_min</th>\n",
       "      <th>split1_train_both_min</th>\n",
       "      <th>split2_train_both_min</th>\n",
       "      <th>split3_train_both_min</th>\n",
       "      <th>split4_train_both_min</th>\n",
       "      <th>mean_train_both_min</th>\n",
       "      <th>std_train_both_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.241802</td>\n",
       "      <td>0.063027</td>\n",
       "      <td>0.080172</td>\n",
       "      <td>0.026122</td>\n",
       "      <td>{0: 1, 1: 0.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 0.0}}</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.037333</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.508337</td>\n",
       "      <td>0.131949</td>\n",
       "      <td>0.071484</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>{0: 1, 1: 0.6896551724137931}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 0.6896551724137931}}</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364457</td>\n",
       "      <td>0.240837</td>\n",
       "      <td>29</td>\n",
       "      <td>0.681529</td>\n",
       "      <td>0.554140</td>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>0.608974</td>\n",
       "      <td>0.576572</td>\n",
       "      <td>0.061957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657090</td>\n",
       "      <td>0.112297</td>\n",
       "      <td>0.087388</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>{0: 1, 1: 1.3793103448275863}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.3793103448275863}}</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430695</td>\n",
       "      <td>0.275246</td>\n",
       "      <td>28</td>\n",
       "      <td>0.789809</td>\n",
       "      <td>0.630573</td>\n",
       "      <td>0.617834</td>\n",
       "      <td>0.636943</td>\n",
       "      <td>0.698718</td>\n",
       "      <td>0.674775</td>\n",
       "      <td>0.063927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.679668</td>\n",
       "      <td>0.099411</td>\n",
       "      <td>0.076131</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>{0: 1, 1: 2.0689655172413794}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.0689655172413794}}</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501677</td>\n",
       "      <td>0.288351</td>\n",
       "      <td>27</td>\n",
       "      <td>0.847134</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>0.687898</td>\n",
       "      <td>0.668790</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.725796</td>\n",
       "      <td>0.067170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.740289</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>0.092265</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>{0: 1, 1: 2.7586206896551726}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.7586206896551726}}</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505186</td>\n",
       "      <td>0.284596</td>\n",
       "      <td>26</td>\n",
       "      <td>0.859873</td>\n",
       "      <td>0.732484</td>\n",
       "      <td>0.707006</td>\n",
       "      <td>0.713376</td>\n",
       "      <td>0.777070</td>\n",
       "      <td>0.757962</td>\n",
       "      <td>0.056541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.675006</td>\n",
       "      <td>0.045288</td>\n",
       "      <td>0.075906</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>{0: 1, 1: 3.4482758620689657}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3.4482758620689657}}</td>\n",
       "      <td>0.004324</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521404</td>\n",
       "      <td>0.284618</td>\n",
       "      <td>25</td>\n",
       "      <td>0.866242</td>\n",
       "      <td>0.777070</td>\n",
       "      <td>0.745223</td>\n",
       "      <td>0.751592</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.043319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.776357</td>\n",
       "      <td>0.108113</td>\n",
       "      <td>0.082616</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>{0: 1, 1: 4.137931034482759}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.137931034482759}}</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522914</td>\n",
       "      <td>0.280202</td>\n",
       "      <td>24</td>\n",
       "      <td>0.872611</td>\n",
       "      <td>0.802548</td>\n",
       "      <td>0.764331</td>\n",
       "      <td>0.757962</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.796012</td>\n",
       "      <td>0.041331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.808553</td>\n",
       "      <td>0.034593</td>\n",
       "      <td>0.090688</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>{0: 1, 1: 4.827586206896552}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.827586206896552}}</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.535856</td>\n",
       "      <td>0.280299</td>\n",
       "      <td>23</td>\n",
       "      <td>0.872611</td>\n",
       "      <td>0.821656</td>\n",
       "      <td>0.783439</td>\n",
       "      <td>0.770701</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.806472</td>\n",
       "      <td>0.037208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.763739</td>\n",
       "      <td>0.045826</td>\n",
       "      <td>0.076183</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>{0: 1, 1: 5.517241379310345}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 5.517241379310345}}</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546105</td>\n",
       "      <td>0.286716</td>\n",
       "      <td>22</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.821656</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.789809</td>\n",
       "      <td>0.785276</td>\n",
       "      <td>0.812720</td>\n",
       "      <td>0.035681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.756591</td>\n",
       "      <td>0.083377</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.006678</td>\n",
       "      <td>{0: 1, 1: 6.206896551724139}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.206896551724139}}</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576491</td>\n",
       "      <td>0.297125</td>\n",
       "      <td>20</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.834395</td>\n",
       "      <td>0.790419</td>\n",
       "      <td>0.788820</td>\n",
       "      <td>0.785276</td>\n",
       "      <td>0.815578</td>\n",
       "      <td>0.036445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.782357</td>\n",
       "      <td>0.133535</td>\n",
       "      <td>0.093233</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>{0: 1, 1: 6.8965517241379315}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.8965517241379315}}</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576485</td>\n",
       "      <td>0.297135</td>\n",
       "      <td>21</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.791411</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.815690</td>\n",
       "      <td>0.034281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.846671</td>\n",
       "      <td>0.104511</td>\n",
       "      <td>0.076249</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>{0: 1, 1: 7.586206896551724}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 7.586206896551724}}</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581479</td>\n",
       "      <td>0.297292</td>\n",
       "      <td>19</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.796407</td>\n",
       "      <td>0.791411</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.817125</td>\n",
       "      <td>0.033661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.772948</td>\n",
       "      <td>0.097185</td>\n",
       "      <td>0.076092</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>{0: 1, 1: 8.275862068965518}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.275862068965518}}</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581484</td>\n",
       "      <td>0.297280</td>\n",
       "      <td>18</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.828221</td>\n",
       "      <td>0.796407</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.815225</td>\n",
       "      <td>0.035512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.935809</td>\n",
       "      <td>0.245386</td>\n",
       "      <td>0.098808</td>\n",
       "      <td>0.023832</td>\n",
       "      <td>{0: 1, 1: 8.965517241379311}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.965517241379311}}</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606732</td>\n",
       "      <td>0.306277</td>\n",
       "      <td>15</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.823171</td>\n",
       "      <td>0.796407</td>\n",
       "      <td>0.784431</td>\n",
       "      <td>0.791908</td>\n",
       "      <td>0.814979</td>\n",
       "      <td>0.034565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.848564</td>\n",
       "      <td>0.161544</td>\n",
       "      <td>0.095505</td>\n",
       "      <td>0.016959</td>\n",
       "      <td>{0: 1, 1: 9.655172413793103}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 9.655172413793103}}</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606740</td>\n",
       "      <td>0.306262</td>\n",
       "      <td>14</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.823171</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.781065</td>\n",
       "      <td>0.787356</td>\n",
       "      <td>0.812938</td>\n",
       "      <td>0.036030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.863977</td>\n",
       "      <td>0.167012</td>\n",
       "      <td>0.080233</td>\n",
       "      <td>0.007622</td>\n",
       "      <td>{0: 1, 1: 10.344827586206897}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.344827586206897}}</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606730</td>\n",
       "      <td>0.306281</td>\n",
       "      <td>16</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.823171</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.773256</td>\n",
       "      <td>0.788571</td>\n",
       "      <td>0.811619</td>\n",
       "      <td>0.037364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.896395</td>\n",
       "      <td>0.165203</td>\n",
       "      <td>0.084294</td>\n",
       "      <td>0.012525</td>\n",
       "      <td>{0: 1, 1: 11.03448275862069}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 11.03448275862069}}</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608582</td>\n",
       "      <td>0.306321</td>\n",
       "      <td>13</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.813253</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.773256</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.808740</td>\n",
       "      <td>0.037509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.807502</td>\n",
       "      <td>0.108438</td>\n",
       "      <td>0.071447</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>{0: 1, 1: 11.724137931034484}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 11.724137931034484}}</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613710</td>\n",
       "      <td>0.310443</td>\n",
       "      <td>9</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.814371</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.764368</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.039354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.921943</td>\n",
       "      <td>0.129460</td>\n",
       "      <td>0.085557</td>\n",
       "      <td>0.023416</td>\n",
       "      <td>{0: 1, 1: 12.413793103448278}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.413793103448278}}</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613708</td>\n",
       "      <td>0.310447</td>\n",
       "      <td>10</td>\n",
       "      <td>0.878981</td>\n",
       "      <td>0.810651</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.806711</td>\n",
       "      <td>0.038960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.878139</td>\n",
       "      <td>0.066875</td>\n",
       "      <td>0.076088</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>{0: 1, 1: 13.10344827586207}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 13.10344827586207}}</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613708</td>\n",
       "      <td>0.310447</td>\n",
       "      <td>11</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.801717</td>\n",
       "      <td>0.035282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.851108</td>\n",
       "      <td>0.097955</td>\n",
       "      <td>0.082443</td>\n",
       "      <td>0.015887</td>\n",
       "      <td>{0: 1, 1: 13.793103448275863}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 13.793103448275863}}</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613702</td>\n",
       "      <td>0.310459</td>\n",
       "      <td>12</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.803057</td>\n",
       "      <td>0.037298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.877638</td>\n",
       "      <td>0.163510</td>\n",
       "      <td>0.095563</td>\n",
       "      <td>0.017092</td>\n",
       "      <td>{0: 1, 1: 14.482758620689657}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.482758620689657}}</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623832</td>\n",
       "      <td>0.314633</td>\n",
       "      <td>5</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.782857</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.794598</td>\n",
       "      <td>0.035813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.835944</td>\n",
       "      <td>0.152721</td>\n",
       "      <td>0.076797</td>\n",
       "      <td>0.005934</td>\n",
       "      <td>{0: 1, 1: 15.172413793103448}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 15.172413793103448}}</td>\n",
       "      <td>0.004090</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623832</td>\n",
       "      <td>0.314633</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.787356</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.797235</td>\n",
       "      <td>0.034165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.878320</td>\n",
       "      <td>0.132753</td>\n",
       "      <td>0.083775</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>{0: 1, 1: 15.862068965517242}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 15.862068965517242}}</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628965</td>\n",
       "      <td>0.317565</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.782857</td>\n",
       "      <td>0.791908</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.792652</td>\n",
       "      <td>0.031247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.906925</td>\n",
       "      <td>0.119594</td>\n",
       "      <td>0.089883</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>{0: 1, 1: 16.551724137931036}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.551724137931036}}</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623832</td>\n",
       "      <td>0.314634</td>\n",
       "      <td>7</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.787356</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.782394</td>\n",
       "      <td>0.031671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.963619</td>\n",
       "      <td>0.185935</td>\n",
       "      <td>0.092684</td>\n",
       "      <td>0.015069</td>\n",
       "      <td>{0: 1, 1: 17.24137931034483}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 17.24137931034483}}</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628963</td>\n",
       "      <td>0.317570</td>\n",
       "      <td>2</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.744565</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.766304</td>\n",
       "      <td>0.775037</td>\n",
       "      <td>0.035678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.002741</td>\n",
       "      <td>0.165351</td>\n",
       "      <td>0.093777</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>{0: 1, 1: 17.931034482758623}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 17.931034482758623}}</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625951</td>\n",
       "      <td>0.316725</td>\n",
       "      <td>4</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.740541</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.740331</td>\n",
       "      <td>0.766304</td>\n",
       "      <td>0.773410</td>\n",
       "      <td>0.037098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.942164</td>\n",
       "      <td>0.141123</td>\n",
       "      <td>0.085695</td>\n",
       "      <td>0.014772</td>\n",
       "      <td>{0: 1, 1: 18.620689655172416}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.620689655172416}}</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626716</td>\n",
       "      <td>0.316856</td>\n",
       "      <td>3</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.736559</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>0.766304</td>\n",
       "      <td>0.768088</td>\n",
       "      <td>0.035542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.966600</td>\n",
       "      <td>0.079872</td>\n",
       "      <td>0.053795</td>\n",
       "      <td>0.022948</td>\n",
       "      <td>{0: 1, 1: 19.310344827586206}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 19.310344827586206}}</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619691</td>\n",
       "      <td>0.313268</td>\n",
       "      <td>8</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>0.774011</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.766304</td>\n",
       "      <td>0.765946</td>\n",
       "      <td>0.040512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.783813</td>\n",
       "      <td>0.058340</td>\n",
       "      <td>0.028480</td>\n",
       "      <td>0.013425</td>\n",
       "      <td>{0: 1, 1: 20.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 20.0}}</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606537</td>\n",
       "      <td>0.308107</td>\n",
       "      <td>17</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.721053</td>\n",
       "      <td>0.765363</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.762162</td>\n",
       "      <td>0.757230</td>\n",
       "      <td>0.032744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.241802      0.063027         0.080172        0.026122   \n",
       "1        0.508337      0.131949         0.071484        0.013026   \n",
       "2        0.657090      0.112297         0.087388        0.011352   \n",
       "3        0.679668      0.099411         0.076131        0.013084   \n",
       "4        0.740289      0.066987         0.092265        0.024668   \n",
       "5        0.675006      0.045288         0.075906        0.007885   \n",
       "6        0.776357      0.108113         0.082616        0.009237   \n",
       "7        0.808553      0.034593         0.090688        0.005739   \n",
       "8        0.763739      0.045826         0.076183        0.010438   \n",
       "9        0.756591      0.083377         0.077590        0.006678   \n",
       "10       0.782357      0.133535         0.093233        0.013203   \n",
       "11       0.846671      0.104511         0.076249        0.008553   \n",
       "12       0.772948      0.097185         0.076092        0.010017   \n",
       "13       0.935809      0.245386         0.098808        0.023832   \n",
       "14       0.848564      0.161544         0.095505        0.016959   \n",
       "15       0.863977      0.167012         0.080233        0.007622   \n",
       "16       0.896395      0.165203         0.084294        0.012525   \n",
       "17       0.807502      0.108438         0.071447        0.007594   \n",
       "18       0.921943      0.129460         0.085557        0.023416   \n",
       "19       0.878139      0.066875         0.076088        0.014645   \n",
       "20       0.851108      0.097955         0.082443        0.015887   \n",
       "21       0.877638      0.163510         0.095563        0.017092   \n",
       "22       0.835944      0.152721         0.076797        0.005934   \n",
       "23       0.878320      0.132753         0.083775        0.007307   \n",
       "24       0.906925      0.119594         0.089883        0.009534   \n",
       "25       0.963619      0.185935         0.092684        0.015069   \n",
       "26       1.002741      0.165351         0.093777        0.006329   \n",
       "27       0.942164      0.141123         0.085695        0.014772   \n",
       "28       0.966600      0.079872         0.053795        0.022948   \n",
       "29       0.783813      0.058340         0.028480        0.013425   \n",
       "\n",
       "               param_class_weight  \\\n",
       "0                  {0: 1, 1: 0.0}   \n",
       "1   {0: 1, 1: 0.6896551724137931}   \n",
       "2   {0: 1, 1: 1.3793103448275863}   \n",
       "3   {0: 1, 1: 2.0689655172413794}   \n",
       "4   {0: 1, 1: 2.7586206896551726}   \n",
       "5   {0: 1, 1: 3.4482758620689657}   \n",
       "6    {0: 1, 1: 4.137931034482759}   \n",
       "7    {0: 1, 1: 4.827586206896552}   \n",
       "8    {0: 1, 1: 5.517241379310345}   \n",
       "9    {0: 1, 1: 6.206896551724139}   \n",
       "10  {0: 1, 1: 6.8965517241379315}   \n",
       "11   {0: 1, 1: 7.586206896551724}   \n",
       "12   {0: 1, 1: 8.275862068965518}   \n",
       "13   {0: 1, 1: 8.965517241379311}   \n",
       "14   {0: 1, 1: 9.655172413793103}   \n",
       "15  {0: 1, 1: 10.344827586206897}   \n",
       "16   {0: 1, 1: 11.03448275862069}   \n",
       "17  {0: 1, 1: 11.724137931034484}   \n",
       "18  {0: 1, 1: 12.413793103448278}   \n",
       "19   {0: 1, 1: 13.10344827586207}   \n",
       "20  {0: 1, 1: 13.793103448275863}   \n",
       "21  {0: 1, 1: 14.482758620689657}   \n",
       "22  {0: 1, 1: 15.172413793103448}   \n",
       "23  {0: 1, 1: 15.862068965517242}   \n",
       "24  {0: 1, 1: 16.551724137931036}   \n",
       "25   {0: 1, 1: 17.24137931034483}   \n",
       "26  {0: 1, 1: 17.931034482758623}   \n",
       "27  {0: 1, 1: 18.620689655172416}   \n",
       "28  {0: 1, 1: 19.310344827586206}   \n",
       "29                {0: 1, 1: 20.0}   \n",
       "\n",
       "                                             params  split0_test_precision  \\\n",
       "0                  {'class_weight': {0: 1, 1: 0.0}}               0.093333   \n",
       "1   {'class_weight': {0: 1, 1: 0.6896551724137931}}               0.005618   \n",
       "2   {'class_weight': {0: 1, 1: 1.3793103448275863}}               0.004759   \n",
       "3   {'class_weight': {0: 1, 1: 2.0689655172413794}}               0.004540   \n",
       "4   {'class_weight': {0: 1, 1: 2.7586206896551726}}               0.004408   \n",
       "5   {'class_weight': {0: 1, 1: 3.4482758620689657}}               0.004324   \n",
       "6    {'class_weight': {0: 1, 1: 4.137931034482759}}               0.004312   \n",
       "7    {'class_weight': {0: 1, 1: 4.827586206896552}}               0.004254   \n",
       "8    {'class_weight': {0: 1, 1: 5.517241379310345}}               0.004214   \n",
       "9    {'class_weight': {0: 1, 1: 6.206896551724139}}               0.004221   \n",
       "10  {'class_weight': {0: 1, 1: 6.8965517241379315}}               0.004194   \n",
       "11   {'class_weight': {0: 1, 1: 7.586206896551724}}               0.004160   \n",
       "12   {'class_weight': {0: 1, 1: 8.275862068965518}}               0.004189   \n",
       "13   {'class_weight': {0: 1, 1: 8.965517241379311}}               0.004147   \n",
       "14   {'class_weight': {0: 1, 1: 9.655172413793103}}               0.004184   \n",
       "15  {'class_weight': {0: 1, 1: 10.344827586206897}}               0.004137   \n",
       "16   {'class_weight': {0: 1, 1: 11.03448275862069}}               0.004122   \n",
       "17  {'class_weight': {0: 1, 1: 11.724137931034484}}               0.004120   \n",
       "18  {'class_weight': {0: 1, 1: 12.413793103448278}}               0.004109   \n",
       "19   {'class_weight': {0: 1, 1: 13.10344827586207}}               0.004109   \n",
       "20  {'class_weight': {0: 1, 1: 13.793103448275863}}               0.004078   \n",
       "21  {'class_weight': {0: 1, 1: 14.482758620689657}}               0.004091   \n",
       "22  {'class_weight': {0: 1, 1: 15.172413793103448}}               0.004090   \n",
       "23  {'class_weight': {0: 1, 1: 15.862068965517242}}               0.004114   \n",
       "24  {'class_weight': {0: 1, 1: 16.551724137931036}}               0.004088   \n",
       "25   {'class_weight': {0: 1, 1: 17.24137931034483}}               0.004102   \n",
       "26  {'class_weight': {0: 1, 1: 17.931034482758623}}               0.004113   \n",
       "27  {'class_weight': {0: 1, 1: 18.620689655172416}}               0.004094   \n",
       "28  {'class_weight': {0: 1, 1: 19.310344827586206}}               0.004157   \n",
       "29                {'class_weight': {0: 1, 1: 20.0}}               0.004056   \n",
       "\n",
       "    split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n",
       "0                0.000000               0.000000               0.000000  ...   \n",
       "1                0.689655               0.954545               1.000000  ...   \n",
       "2                0.735294               0.961538               0.928571  ...   \n",
       "3                0.769231               0.962963               0.933333  ...   \n",
       "4                0.761905               0.962963               0.933333  ...   \n",
       "5                0.767442               0.964286               0.933333  ...   \n",
       "6                0.750000               0.964286               0.933333  ...   \n",
       "7                0.739130               0.964286               0.935484  ...   \n",
       "8                0.739130               0.966667               0.935484  ...   \n",
       "9                0.739130               0.966667               0.941176  ...   \n",
       "10               0.739130               0.935484               0.941176  ...   \n",
       "11               0.739130               0.935484               0.941176  ...   \n",
       "12               0.739130               0.935484               0.941176  ...   \n",
       "13               0.739130               0.967742               0.942857  ...   \n",
       "14               0.739130               0.937500               0.916667  ...   \n",
       "15               0.739130               0.937500               0.916667  ...   \n",
       "16               0.723404               0.937500               0.942857  ...   \n",
       "17               0.723404               0.937500               0.944444  ...   \n",
       "18               0.723404               0.937500               0.944444  ...   \n",
       "19               0.723404               0.937500               0.944444  ...   \n",
       "20               0.723404               0.937500               0.944444  ...   \n",
       "21               0.723404               0.939394               0.944444  ...   \n",
       "22               0.723404               0.939394               0.944444  ...   \n",
       "23               0.723404               0.941176               0.918919  ...   \n",
       "24               0.723404               0.939394               0.894737  ...   \n",
       "25               0.723404               0.941176               0.894737  ...   \n",
       "26               0.708333               0.941176               0.871795  ...   \n",
       "27               0.708333               0.942857               0.850000  ...   \n",
       "28               0.693878               0.942857               0.829268  ...   \n",
       "29               0.653846               0.914286               0.829268  ...   \n",
       "\n",
       "    mean_test_both_min  std_test_both_min  rank_test_both_min  \\\n",
       "0             0.018667           0.037333                  30   \n",
       "1             0.364457           0.240837                  29   \n",
       "2             0.430695           0.275246                  28   \n",
       "3             0.501677           0.288351                  27   \n",
       "4             0.505186           0.284596                  26   \n",
       "5             0.521404           0.284618                  25   \n",
       "6             0.522914           0.280202                  24   \n",
       "7             0.535856           0.280299                  23   \n",
       "8             0.546105           0.286716                  22   \n",
       "9             0.576491           0.297125                  20   \n",
       "10            0.576485           0.297135                  21   \n",
       "11            0.581479           0.297292                  19   \n",
       "12            0.581484           0.297280                  18   \n",
       "13            0.606732           0.306277                  15   \n",
       "14            0.606740           0.306262                  14   \n",
       "15            0.606730           0.306281                  16   \n",
       "16            0.608582           0.306321                  13   \n",
       "17            0.613710           0.310443                   9   \n",
       "18            0.613708           0.310447                  10   \n",
       "19            0.613708           0.310447                  11   \n",
       "20            0.613702           0.310459                  12   \n",
       "21            0.623832           0.314633                   5   \n",
       "22            0.623832           0.314633                   6   \n",
       "23            0.628965           0.317565                   1   \n",
       "24            0.623832           0.314634                   7   \n",
       "25            0.628963           0.317570                   2   \n",
       "26            0.625951           0.316725                   4   \n",
       "27            0.626716           0.316856                   3   \n",
       "28            0.619691           0.313268                   8   \n",
       "29            0.606537           0.308107                  17   \n",
       "\n",
       "    split0_train_both_min  split1_train_both_min  split2_train_both_min  \\\n",
       "0                0.000000               0.000000               0.000000   \n",
       "1                0.681529               0.554140               0.522293   \n",
       "2                0.789809               0.630573               0.617834   \n",
       "3                0.847134               0.675159               0.687898   \n",
       "4                0.859873               0.732484               0.707006   \n",
       "5                0.866242               0.777070               0.745223   \n",
       "6                0.872611               0.802548               0.764331   \n",
       "7                0.872611               0.821656               0.783439   \n",
       "8                0.878981               0.821656               0.787879   \n",
       "9                0.878981               0.834395               0.790419   \n",
       "10               0.878981               0.825000               0.795181   \n",
       "11               0.878981               0.827160               0.796407   \n",
       "12               0.878981               0.828221               0.796407   \n",
       "13               0.878981               0.823171               0.796407   \n",
       "14               0.878981               0.823171               0.794118   \n",
       "15               0.878981               0.823171               0.794118   \n",
       "16               0.878981               0.813253               0.794118   \n",
       "17               0.878981               0.814371               0.794118   \n",
       "18               0.878981               0.810651               0.794118   \n",
       "19               0.867925               0.801170               0.794118   \n",
       "20               0.873418               0.801170               0.795322   \n",
       "21               0.862500               0.782857               0.795322   \n",
       "22               0.862500               0.787356               0.795322   \n",
       "23               0.851852               0.782857               0.791908   \n",
       "24               0.841463               0.761111               0.787356   \n",
       "25               0.841463               0.744565               0.778409   \n",
       "26               0.841463               0.740541               0.778409   \n",
       "27               0.831325               0.736559               0.774011   \n",
       "28               0.836364               0.732620               0.774011   \n",
       "29               0.811765               0.721053               0.765363   \n",
       "\n",
       "    split3_train_both_min  split4_train_both_min  mean_train_both_min  \\\n",
       "0                0.000000               0.000000             0.000000   \n",
       "1                0.515924               0.608974             0.576572   \n",
       "2                0.636943               0.698718             0.674775   \n",
       "3                0.668790               0.750000             0.725796   \n",
       "4                0.713376               0.777070             0.757962   \n",
       "5                0.751592               0.779874             0.784000   \n",
       "6                0.757962               0.782609             0.796012   \n",
       "7                0.770701               0.783951             0.806472   \n",
       "8                0.789809               0.785276             0.812720   \n",
       "9                0.788820               0.785276             0.815578   \n",
       "10               0.791411               0.787879             0.815690   \n",
       "11               0.791411               0.791667             0.817125   \n",
       "12               0.781818               0.790698             0.815225   \n",
       "13               0.784431               0.791908             0.814979   \n",
       "14               0.781065               0.787356             0.812938   \n",
       "15               0.773256               0.788571             0.811619   \n",
       "16               0.773256               0.784091             0.808740   \n",
       "17               0.764368               0.784091             0.807186   \n",
       "18               0.765714               0.784091             0.806711   \n",
       "19               0.765714               0.779661             0.801717   \n",
       "20               0.765714               0.779661             0.803057   \n",
       "21               0.761364               0.770950             0.794598   \n",
       "22               0.765714               0.775281             0.797235   \n",
       "23               0.761364               0.775281             0.792652   \n",
       "24               0.752809               0.769231             0.782394   \n",
       "25               0.744444               0.766304             0.775037   \n",
       "26               0.740331               0.766304             0.773410   \n",
       "27               0.732240               0.766304             0.768088   \n",
       "28               0.720430               0.766304             0.765946   \n",
       "29               0.725806               0.762162             0.757230   \n",
       "\n",
       "    std_train_both_min  \n",
       "0             0.000000  \n",
       "1             0.061957  \n",
       "2             0.063927  \n",
       "3             0.067170  \n",
       "4             0.056541  \n",
       "5             0.043319  \n",
       "6             0.041331  \n",
       "7             0.037208  \n",
       "8             0.035681  \n",
       "9             0.036445  \n",
       "10            0.034281  \n",
       "11            0.033661  \n",
       "12            0.035512  \n",
       "13            0.034565  \n",
       "14            0.036030  \n",
       "15            0.037364  \n",
       "16            0.037509  \n",
       "17            0.039354  \n",
       "18            0.038960  \n",
       "19            0.035282  \n",
       "20            0.037298  \n",
       "21            0.035813  \n",
       "22            0.034165  \n",
       "23            0.031247  \n",
       "24            0.031671  \n",
       "25            0.035678  \n",
       "26            0.037098  \n",
       "27            0.035542  \n",
       "28            0.040512  \n",
       "29            0.032744  \n",
       "\n",
       "[30 rows x 51 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(grid.cv_results_)\n",
    "df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2710213e-1a35-4fba-b157-7a14544026ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize  =(12,4))\n",
    "for score in ['mean_test_recall','mean_test_precision','mean_train_both_min'] : \n",
    "    plt.plot([ _[1] for _ in df['param_class_weight']], \n",
    "            df[score] ,\n",
    "            label = score)\n",
    "plt.legend() ; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee95ef-2c35-4f4c-9753-c10722ee558d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
